[
  {
    "objectID": "alphabeta.html",
    "href": "alphabeta.html",
    "title": "Simulations exploring alpha and beta diversity",
    "section": "",
    "text": "This file will include short simulations to understand how differences in community compositions are reflected in alpha and beta diversity metrics.\nIn each simulation I’ll create some data with given characteristics then look at how this is reflected in the diversity measures. This could be extended into power calculations if needed."
  },
  {
    "objectID": "alphabeta.html#simulation-1",
    "href": "alphabeta.html#simulation-1",
    "title": "Simulations exploring alpha and beta diversity",
    "section": "Simulation 1",
    "text": "Simulation 1\n\nWe’ll assume that there are 100 possible species in my communities.\nThere are two different classes of environments from which we can sample communities,\nIn samples from the first environment each species is present with probability 0.4.\nIn samples from the the second environment each species is present with probability 0.6.\n\nStep 1: sample a matrix of the community compositions:\n\nN = 10 # Number of samples per class\nn = 100 # Number of possible species\nset.seed(\"19122023\")\nclasses &lt;- rep(c(\"A\", \"B\"), each=N)\nclassProbabilities &lt;- c(\"A\"=0.4,\"B\"=0.5)\ndat &lt;- sapply(classes, \\(class) rbinom(n=n, size = 1, p=classProbabilities[class])) |&gt; t()\n\nNow look at the alpha diversity (Shannon index):\n\nlibrary(vegan)\nlibrary(ggplot2)\n## Shannon index\nt.test(diversity(dat) ~ classes)\n\n\n    Welch Two Sample t-test\n\ndata:  diversity(dat) by classes\nt = -4.6706, df = 16.102, p-value = 0.0002517\nalternative hypothesis: true difference in means between group A and group B is not equal to 0\n95 percent confidence interval:\n -0.3544225 -0.1332105\nsample estimates:\nmean in group A mean in group B \n       3.672421        3.916238 \n\nggplot() + aes(y=diversity(dat), x=classes) + \n  geom_boxplot()  +\n  geom_point() + \n  stat_summary()\n\n\n\n\nBeta-diversity (NMDS following Jaccard diversity):\n\n## Not so clear with the beta-diversity\nvegdist(dat, method = \"jaccard\", binary = TRUE) |&gt; \n  metaMDS(trace = 0) |&gt;\n  scores() |&gt; \n  plot(col=factor(classes), pch=20)\n  legend(\"topright\", legend=c(\"A\",\"B\"), col=1:2,pch=20)\n\n\n\ndm1 &lt;- vegdist(dat, method = \"jaccard\", binary = TRUE)\nadonis2(dm1 ~ classes  )  \n\nPermutation test for adonis under reduced model\nTerms added sequentially (first to last)\nPermutation: free\nNumber of permutations: 999\n\nadonis2(formula = dm1 ~ classes)\n         Df SumOfSqs      R2      F Pr(&gt;F)\nclasses   1   0.2915 0.06188 1.1873  0.166\nResidual 18   4.4193 0.93812              \nTotal    19   4.7108 1.00000              \n\nanosim(dm1, grouping = classes)\n\n\nCall:\nanosim(x = dm1, grouping = classes) \nDissimilarity: binary jaccard \n\nANOSIM statistic R: 0.02167 \n      Significance: 0.36 \n\nPermutation: free\nNumber of permutations: 999\n\n\nSo in this case we see a clear difference in alpha diversity between sites but it’s not so clear for beta diversity. It looks like the environment B samples are slightly more clustered while the A samples are more spread out. The difference is not reflected in a PERMANOVA (via adonis2) or ANOSIM.\nThis is a good reminder that important differences in community composition might not be visible in beta diversity plots. Maybe you all know that anyway but it was a good reminder for me."
  },
  {
    "objectID": "berkson.html",
    "href": "berkson.html",
    "title": "Selection bias in observational studies",
    "section": "",
    "text": "This is a short illustration of “Berkson bias” using simulated data. This is the phenomenon that selection bias can induce correlations in samples that are not present in populations.\nThis bias is likely to be an issue for many observational studies but is not well understood in the medical research literature.\nThe Wikipedia page for the phenonomenon is here: https://en.wikipedia.org/wiki/Berkson%27s_paradox\n\nSelection bias in observational studies\nSuppose we are trying to understand the correlation between health and wealth.\nFirst, let’s simulation a population in which health and wealth are both normally distributed but are not correlated with each other:\n\nset.seed(1)\npopulationsize = 1e4\nsamplesize = 200\n\npopulation &lt;- data.frame(health=rnorm(populationsize), wealth=rnorm(populationsize))\nplot(population)\n\n\n\n\nNow if we take a simple random sample from this cohort from this group and test the correlation…\n\nsample1 &lt;- population[sample(populationsize, samplesize),]\nplot(sample1$health, sample1$wealth)\n\n\n\ncor.test(sample1$health, sample1$wealth)\n\n\n    Pearson's product-moment correlation\n\ndata:  sample1$health and sample1$wealth\nt = -0.78426, df = 198, p-value = 0.4338\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.19290026  0.08373896\nsample estimates:\n        cor \n-0.05564858 \n\n\nWe see no evidence that wealth and health are related, as we would expect given this is true in the population.\nHowever we know that healthier, wealthier people are more likely to participate in our studies. So let’s create a sample that reflects this:\n\npopulation$b_participate = (population$health + population$wealth)\npopulation$prob_participate = exp(population$b_participate) / (1+exp(population$b_participate))\n\nsample2 &lt;- population[sample(populationsize, samplesize, prob = population$prob_participate),]\n\nHow will the average health and wealth in our sample compare to the population?\n\nmean(sample2$health)\n\n[1] 0.3808598\n\nmean(sample2$wealth)\n\n[1] 0.3049277\n\n\nWell we know that health and wealth are higher in the sample than the population, but this should hopefullt be obvious. But how are the two things correlated in the population?\n\nplot(sample2$health, sample2$wealth)\n\n\n\ncor.test(sample2$health, sample2$wealth)\n\n\n    Pearson's product-moment correlation\n\ndata:  sample2$health and sample2$wealth\nt = -2.9629, df = 198, p-value = 0.003421\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.3352015 -0.0692823\nsample estimates:\n       cor \n-0.2060428 \n\n\nIt looks like a negative correlation in the sample, despite there being no correlation in the population!\nWas this unlucky? We can look at the distribution of p-values from repeated samples, to see what the chance of a false positive correlation is here:\n\nonepvalue &lt;- function(){\n  samplen &lt;- population[sample(populationsize, samplesize, prob = population$prob_participate),]\n  cor.test(samplen$health, samplen$wealth)$p.value\n}\nreplicate(1000, onepvalue()) |&gt; hist(breaks=20)\n\n\n\n\nIn more than 50% of cases there is now a significant correlation in the sample even though there is no correlation in the population. It is simply caused by the factors under investigation also being factors that lead people to participate in research.\nWhat are the implications of this for observational studies?\nWhat can we do about it?"
  },
  {
    "objectID": "datatabletidyverse.html",
    "href": "datatabletidyverse.html",
    "title": "Descriptive tables using base R, data.table and tidyverse",
    "section": "",
    "text": "With only base R (that is, R without add on packages) it can be unexpectedly difficult to perform some simple tasks.\nA good example is making a table of summary statistics. This is difficult with base R but is simple with using function from add-on packages.\nHere I illustrate this using two widely used systems for data manipulation in R, namely data.table and tidyverse. Both can be used to make summary tables of descriptive statistics. that can be exported\nFinally I describe a package, gtsummary that is specifically designed for creation of publication ready summary tables."
  },
  {
    "objectID": "datatabletidyverse.html#breaking-down-the-data.table-syntax",
    "href": "datatabletidyverse.html#breaking-down-the-data.table-syntax",
    "title": "Descriptive tables using base R, data.table and tidyverse",
    "section": "Breaking down the data.table syntax",
    "text": "Breaking down the data.table syntax\nThe [ operator in data.table has three arguments. In short, we express a command on a dataset (here called dat) by specifying:\n\ndat[ which rows to use , what to do , which columns to group on ]\n\nIn the first version of the command above we left the first entry blank (so used all the rows), placed mean(height) in the second position and specified by=sex in the third. In the second version we expanded the second argument to return a list of elements, and gave them new names.\nFor more details of using data.table, see: https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html"
  },
  {
    "objectID": "datatabletidyverse.html#the-tidyverse-dplyr-syntax",
    "href": "datatabletidyverse.html#the-tidyverse-dplyr-syntax",
    "title": "Descriptive tables using base R, data.table and tidyverse",
    "section": "The tidyverse (dplyr) syntax",
    "text": "The tidyverse (dplyr) syntax\ndplyr introduces six main functions for manipulating and summarising data, these are mutate, arrange, select, filter, summarise, and group_by. Using combinations of these functions you can perform most simple data operations. Functions are chained together using the pipe operator %&gt;% which passes the output from one into the next.\nSo the first command above reads something like: “take dat, then group it by sex, then for each group return the summary statistics we specified”.\nVisit https://www.tidyverse.org/learn for more."
  },
  {
    "objectID": "day1.html",
    "href": "day1.html",
    "title": "Introduction to ‘R’ for statistical analysis",
    "section": "",
    "text": "This course will introduce\n\nR and RStudio statistical software\nexamples of performing common tasks in scientific data analysis\nwhere to go for further support\n\nThe aim is to become familiar with the R/RStudio environment and some common functions and workflows. This will enable you to learn the specific functions that you need on your own or with further training.\nAll of the commands for the worked examples and the exercises is in the file TutorialScript.R. The commands for the worked examples are also typed out here.\nPowerpoint slides for today’s session are here:\n\nDay 1 slides\n\nThis handout was written in RStudio using the Quarto document preparation system. The source code is here: day1.qmd\n\n\nWe will focus on the tasks used in a typical analysis of a single scientific dataset, mirroring the tasks usually conducted in other statistical software.\n\n\nDay 1: R and RStudio basics\n\nFamiliarity with R and RStudio\nExploring data and calculating descriptive statistics\n\nDay 2: Some more statistics\n\nRevise and consolidate day 1 learning\nLoading and wrangling data\nSimple hypothesis tests\n\nDay 3: Linear models using R with real data\n\nEstimating, diagnosing and interpreting linear models\nMaking graphs using the ggplot2 package"
  },
  {
    "objectID": "day1.html#learning-objectives",
    "href": "day1.html#learning-objectives",
    "title": "Introduction to ‘R’ for statistical analysis",
    "section": "",
    "text": "We will focus on the tasks used in a typical analysis of a single scientific dataset, mirroring the tasks usually conducted in other statistical software.\n\n\nDay 1: R and RStudio basics\n\nFamiliarity with R and RStudio\nExploring data and calculating descriptive statistics\n\nDay 2: Some more statistics\n\nRevise and consolidate day 1 learning\nLoading and wrangling data\nSimple hypothesis tests\n\nDay 3: Linear models using R with real data\n\nEstimating, diagnosing and interpreting linear models\nMaking graphs using the ggplot2 package"
  },
  {
    "objectID": "day1.html#what-are-r-and-rstudio",
    "href": "day1.html#what-are-r-and-rstudio",
    "title": "Introduction to ‘R’ for statistical analysis",
    "section": "2.1 What are R and RStudio?",
    "text": "2.1 What are R and RStudio?\nR is a free and open source statistics package, initially developed during the 1990s, and that has now become the world’s most widely used and comprehensive statistical software. R calls itself a programming language and environment for statistic computing.\nThat is, ‘R’ refers both to the software itself and the programming language that you use to interact with it.\nRStudio is a free open source integrated development environment (IDE) for R that makes working R much easier. Most R users use RStudio and we recommend using RStudio for new users.\nThe great strength of R is in its contributed packages, these are community written add-ons that make R much more powerful and easy to use. We will introduce some commonly used packages for data management, analysis and graphing during this course."
  },
  {
    "objectID": "day1.html#getting-r-and-rstudio",
    "href": "day1.html#getting-r-and-rstudio",
    "title": "Introduction to ‘R’ for statistical analysis",
    "section": "2.2 Getting R and RStudio",
    "text": "2.2 Getting R and RStudio\n\nIf you are using a PC in the JIC IT training suite it will already have an up-to-date version of R and RStudio.\nFor other NBI managed devices you can install R and RStudio from the NBI software catalogue.\nIf you want to install R and RStudio on your own device:\n\nDownload and install the latest version of R from https://cran.r-project.org/\nThen download and install RStudio from https://www.rstudio.com/"
  },
  {
    "objectID": "day1.html#starting-rstudio",
    "href": "day1.html#starting-rstudio",
    "title": "Introduction to ‘R’ for statistical analysis",
    "section": "2.3 Starting RStudio",
    "text": "2.3 Starting RStudio\nStart RStudio. It will detect your installation of R, and you should see a screen like this:\n\n\n\nFigure: RStudio Window\n\n\nOn the left is the console window, where you type commands and see output. The windows on the right hold various useful tabs, including your data, graphs, help files, and your command history."
  },
  {
    "objectID": "day1.html#check-r-and-rstudio-are-working-run-your-first-command",
    "href": "day1.html#check-r-and-rstudio-are-working-run-your-first-command",
    "title": "Introduction to ‘R’ for statistical analysis",
    "section": "2.4 Check R and RStudio are working, run your first command",
    "text": "2.4 Check R and RStudio are working, run your first command\n\nClick in the console window and type:\n\n\n1+2\n\nPress return on your keyboard. You should see:\n\n\n[1] 3\n\n\n\nTry a few other mathematical functions at the R console (eg):\n\n\nsin(pi/2)\nlog(10)\nexp(2)\n1e4\n1/0"
  },
  {
    "objectID": "day1.html#making-a-script",
    "href": "day1.html#making-a-script",
    "title": "Introduction to ‘R’ for statistical analysis",
    "section": "3.1 Making a script",
    "text": "3.1 Making a script\nWe could do everything by typing commands into the console window as we have already seen, but this is not good if we want to remember or repeat something we have done, or share it with others.\nSo instead we will type our commands into files called R scripts and run the commands from there. With a script you can run and re-run bigger analyses that chain together all the functions you need for data loading, cleaning, analysing, reporting etc.\nUsing scripts mean we can develop complex analyses, and that when we come back to them later, eg if something changes in our data that means we need to redo everything, or we want to tweak something in our analysis because of a reviewer’s comment, we can easily do this.\n\nIt is good to keep a separate R script for each analysis that you do, such that each starts with the functions to load the required data, then do any cleaning or coding that is necessary, then to perform and report the data analysis.\nIf you start making more complex projects you may want to write separate scripts for each of these elements.\n\nAn example R script, annotated with comments, is in the files that accompany this handout.\n\n3.1.1 Make a script\n\nMake a new script. Click on File → New File → R Script in the main RStudio window. An empty file will appear in the top-left pane.\nSave your script with a sensible filename (even though it is empty). Having unsaved scripts is a bad idea, RStudio is sometimes unstable and while it will try to recover unsaved work it is not always guaranteed to. Get into the habit of saving your scripts regularly. Make sure it has the file extension .R\nPut some of the mathematical functions that you have already tried into your script, with one on each line.\n\nYou can now run code from scripts in several ways. Try each of these:\n\nPress ‘run’ or type Ctrl+Enter on the keyboard, RStudio will send the line that the cursor is on to the R console and will run it.\nIf you highlight an area of the script and then hit ‘run’ (or press Ctrl+Enter) then RStudio will send all the highlighted code to the R console.\nIf you save the file, then press ‘source’, R will load the file from disk and run all the commands from that file in sequence.\n\nIf you have your raw data saved, and you keep your scripts, then you don’t need to save your results or any of the variables that you generated or modified during your analysis. So long as the original data doesn’t change, running the script will reproduce all of your analysis and output. This is usually a better way of working than trying to save your environment with all of your results and tables in.\nI have created a script including all the analyses from this tutorial, in TutorialScript.R. Open this and have a look around. Notice my comments to remind myself why I did things, this might be helpful when I next come to revise the analysis!\nSee:\n\nhttps://kdestasio.github.io/post/r_best_practices/\nhttps://r4ds.had.co.nz/workflow-projects.html\nhttps://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects\nhttps://rstats.wtf\n\nfor more information on using projects and scripts"
  },
  {
    "objectID": "day1.html#functions",
    "href": "day1.html#functions",
    "title": "Introduction to ‘R’ for statistical analysis",
    "section": "4.1 Functions",
    "text": "4.1 Functions\nEverything in R is done by executing ‘functions’. When you typed 1+2 at the console above you were calling the + function, with 1 and 2 as its arguments, and the result was printed in the console window.\nSimple mathematical functions can be written using standard notation in this way (eg 1+2 or 3/4) but functions are more commonly called by their name, with their arguments in brackets, separated by commas. For example, to get say the logarithm (base 10) of 100, we would type\n\n### Try this directly in the console, and by running it from your new script.\nlog(x=100, base=10)\n\n[1] 2\n\n\nHere, log is the name of the function, with x and base its arguments. The result is the value of the function (the value is what is returned).\n\nTry each of the following commands. Do you understand what they do any why?\n\n\n### From now on, keep everything you try in a script file.\n\nlog(x=100, base=10)\nlog(x=100)\nlog(base=10, x=100)\n\nlog(100,10)\nlog(10,100)\n\n1000 |&gt; log()           #  Note the use of the pipe operator |&gt; as an alternative way to call a function. \n100 |&gt; log(base=10)\n\nlog()\nlog\n\n\n4.1.1 Getting help\nIn the console, type:\n\n?log\n\nto read the help file for the log function. All R help files are structured in this way. Look at the Usage, Arguments and Value sections. These will be invaluable when you come to use R and use functions that you do not already know."
  },
  {
    "objectID": "day1.html#objects",
    "href": "day1.html#objects",
    "title": "Introduction to ‘R’ for statistical analysis",
    "section": "4.2 Objects",
    "text": "4.2 Objects\nInstead of directly displaying the value of the function (‘value’ is what R calls the result of a function), you can give it a name and store it for later use:\n\nx = 1+2\n\nor\n\nx &lt;- 1+2\n\nThis does exactly the same thing; some R users use the arrow &lt;- instead of = for assignment, so both forms will come up when you’re looking at help files or other people’s code. I (annoyingly!) tend to use either interchangeably.\nNow you have an object called x in your environment that holds the number 3 (check your environment window). You can ask R to display the value of ‘x’ by just entering x (just entering the name of an object prints that object):\n\nx\n\nOr you could do something else with x\n\nx*2\nlog(x)\nx |&gt; log()\nx |&gt; log(10)\n\nWhat does this do?\n\nx |&gt; log() |&gt; sqrt()\n\nHint: it might help to understand if you read the pipe operator |&gt; as “and then…”\nTo see the class of an object (what kind of thing is stored in the object), use the class() function.\n\nclass(x)\n\nObjects of different classes store different kinds of information. We will come across objects of different classes later."
  },
  {
    "objectID": "day1.html#test-yourself",
    "href": "day1.html#test-yourself",
    "title": "Introduction to ‘R’ for statistical analysis",
    "section": "4.3 Test yourself",
    "text": "4.3 Test yourself\n\nMake a new object called y which has the value of x+3. Then display y.\nNow change the value of x (eg using x &lt;- 6 ). Does the value of y change?\nObjects can hold text strings instead of numbers. Try:\n\n\nmyname &lt;- \"George\"  #(or whatever your name is).\nmyname\n\nWhat is the class of the ‘myname’ object?\n\n(Difficult!) Look up the function to turn a text string into upper case (an internet search will help you). Use this function to make a new object which has the same text as ‘myname’ but in upper case."
  },
  {
    "objectID": "day1.html#explore-the-structure-of-the-dataset",
    "href": "day1.html#explore-the-structure-of-the-dataset",
    "title": "Introduction to ‘R’ for statistical analysis",
    "section": "5.1 Explore the structure of the dataset",
    "text": "5.1 Explore the structure of the dataset\nStart a new script to begin your analysis of the ‘iris’ dataset.\nType:\n\ndata(iris)\n\nCheck your ‘environment’ tab for a new object. Click on the object name to see it in the Viewer, or click on the small blue button next to it to expand the view in the environment window.\nWhat is the class of the iris object that you have created?\nWhat is in this data? What kind of descriptive statistics might we calculate to learn about this dataset?\nThere are a few different functions you can use to explore a dataset. Test each to see what they do.\n\nstr(iris)\nhead(iris)\nsummary(iris)\ndim(iris)\nnrow(iris)\nView(iris)\n\nThe iris data is an example of a dataset in tidy form. We’ll learn more about this in the next session, but in short in has:\n\nA single rectangular table to represent the data\nA column for each variable\nA row for each observation\n\nThis is very similar to how datasets are stored in software like SPSS or Stata, or in a database, but is different to how you might record data using GraphPad Prism."
  },
  {
    "objectID": "day1.html#use-the-data-in-calculations",
    "href": "day1.html#use-the-data-in-calculations",
    "title": "Introduction to ‘R’ for statistical analysis",
    "section": "5.2 Use the data in calculations",
    "text": "5.2 Use the data in calculations\nWe can extract individual variables (characteristics) and individual elements like this:\n\niris$Sepal.Length \n\n## What do these lines do?\n\niris$Sepal.Length[1]\n\niris$Sepal.Length[c(2,4,6)]\n\niris$Sepal.Length[10:20]\n\n## What do these lines do?\n\nc(2,4,6)\n\n10:20\n\n## What does this do?\n\nplot(iris, col=iris$Species)\n\n\n\n\n\n\n\nNote\n\n\n\niris$Sepal.length is a ‘vector’. A vector is a list of items all of the same type. Here its a vector of numbers. A data frame is a collection of vectors.\nWhat are the types of each of the other vectors in the iris data frame?\n\n\nWe can use functions to get descriptive statistics for a vector:\n\nmean(iris$Sepal.Length)\n\niris$Sepal.Length |&gt; mean()\n\nsd(iris$Sepal.Length)\n\niris$Sepal.Width |&gt; hist()\n\nCan you make a histogram with red bars?\nWe can work on more than one variable at a time:\n\ncor(iris$Sepal.Length, iris$Sepal.Width)\n\ncor.test(iris$Sepal.Length, iris$Sepal.Width)\n\n\nwith(iris , cor(Sepal.Length , Sepal.Width))"
  },
  {
    "objectID": "day1.html#test-yourself---more-exploration-of-the-iris-dataset",
    "href": "day1.html#test-yourself---more-exploration-of-the-iris-dataset",
    "title": "Introduction to ‘R’ for statistical analysis",
    "section": "5.3 Test yourself - More exploration of the iris dataset",
    "text": "5.3 Test yourself - More exploration of the iris dataset\n\nHow many rows does the iris dataset have?\nWhat is the class of each of its columns?\nWhat is the mean sepal length of the flowers\nWhat is the smallest (minimum) sepal width\n(Difficult) How many viriginca flowers are included in the dataset? Can you tabulate the species variable?\nCan you make a cow say the median petal length?"
  },
  {
    "objectID": "day1.html#other-packages-for-descriptive-statistics-if-you-have-time",
    "href": "day1.html#other-packages-for-descriptive-statistics-if-you-have-time",
    "title": "Introduction to ‘R’ for statistical analysis",
    "section": "5.4 Other packages for descriptive statistics (if you have time)",
    "text": "5.4 Other packages for descriptive statistics (if you have time)\n(If we have time) Base R does not have good functions for making descriptive tables and graphs. But there are many other packages that have been developed to help with this. In particular the gt system is very good for making tables, and the GGally package has a nice function for making pairs plots. You could install these packages and try them out:\n\ninstall.packages(\"gtsummary\")\ngtsummary::tbl_summary(iris)\n\nCan you stratify the table by species? (Check the help)\n\ninstall.packages(\"GGally\")\nGGally::ggpairs(iris)\n\nCompare this to the output from the ‘base’ function pairs(iris) or plot(iris)."
  },
  {
    "objectID": "day1.html#using-dplyr-functions-to-manipulate-and-summarise-data",
    "href": "day1.html#using-dplyr-functions-to-manipulate-and-summarise-data",
    "title": "Introduction to ‘R’ for statistical analysis",
    "section": "6.1 Using dplyr functions to manipulate and summarise data",
    "text": "6.1 Using dplyr functions to manipulate and summarise data\nThe five main dplyr functions are select, filter, mutate, group_by, and summarise.\nLet’s learn by example what each of these functions does:\n\niris |&gt; select(Sepal.Length, Sepal.Width)\n\niris |&gt; filter(Species==\"setosa\")\n\niris |&gt; filter(Sepal.Length &gt; 7.5)\n\niris |&gt; arrange(Sepal.Length)\n\niris |&gt; summarise(`Median Petal Width` = median(Petal.Width))\n\niris |&gt; summarise(`Mean` = median(Petal.Width), `SD` = sd(Petal.Width))\n\niris |&gt; mutate(Sepal.Area = Sepal.Length * Sepal.Width)\n\niris2 &lt;- iris |&gt; mutate(logPetalLength = log(Petal.Length))\n\niris2 &lt;- iris |&gt; mutate(PetalLengthGrouped = ntile(Petal.Length) )\n\nSo with dplyr we can take subsets of our data or our samples, split our samples up into groups, create new derived variables and make summary statistics.\nUsing pipes you can chain functions together. Suppose you wanted the mean sepal length of setosa flowers:\n\niris |&gt; filter(Species==\"setosa\") |&gt; summarise(mean(Sepal.Length))\n\ngroup_by and summarise are often used together, to make summaries over groups.\n\niris |&gt; group_by(Species) |&gt; summarise(mean(Sepal.Length), mean(Sepal.Width), n=n())"
  },
  {
    "objectID": "day1.html#test-yourself-data-wrangling-and-summarising",
    "href": "day1.html#test-yourself-data-wrangling-and-summarising",
    "title": "Introduction to ‘R’ for statistical analysis",
    "section": "6.2 Test yourself: data wrangling and summarising",
    "text": "6.2 Test yourself: data wrangling and summarising\nCan you use dplyr to find the mean of the sepal length for flowers with a petal length less than 2?"
  },
  {
    "objectID": "day1.html#test-yourself-1",
    "href": "day1.html#test-yourself-1",
    "title": "Introduction to ‘R’ for statistical analysis",
    "section": "8.1 Test yourself",
    "text": "8.1 Test yourself\n\nCan you estimate the linear model and display the summary in one line using pipes?\nHow much of the output summary do you understand?\n\n\n# Base R methods:\nconfint(model1)\n\n                      2.5 %   97.5 %\n(Intercept)       4.8621258 5.149874\nSpeciesversicolor 0.7265312 1.133469\nSpeciesvirginica  1.3785312 1.785469\n\n# Tidyverse method:\nbroom::tidy(model1, conf.int=TRUE)\n\n# A tibble: 3 × 7\n  term              estimate std.error statistic   p.value conf.low conf.high\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)          5.01     0.0728     68.8  1.13e-113    4.86       5.15\n2 Speciesversicolor    0.930    0.103       9.03 8.77e- 16    0.727      1.13\n3 Speciesvirginica     1.58     0.103      15.4  2.21e- 32    1.38       1.79\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote - you can run t-tests like this, since a t-test is equivalent to a linear model with two group categorical predictor.\n\n\nAll pairwise comparisons using emmeans or t-tests for individual pairs with filter then lm?\n\n8.1.1 More complex models\nNow. suppose we want to fit a more complex model, whereby sepal length depends on petal length, with the relationship allowed to vary by species.\n\n# First make a model with Sepal.Length depending on Species and Petal.Length\nmodel2 &lt;- lm( Sepal.Length ~ Species + Petal.Length, data=iris)\nsummary(model2)\n\n\nCall:\nlm(formula = Sepal.Length ~ Species + Petal.Length, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.75310 -0.23142 -0.00081  0.23085  1.03100 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        3.68353    0.10610  34.719  &lt; 2e-16 ***\nSpeciesversicolor -1.60097    0.19347  -8.275 7.37e-14 ***\nSpeciesvirginica  -2.11767    0.27346  -7.744 1.48e-12 ***\nPetal.Length       0.90456    0.06479  13.962  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.338 on 146 degrees of freedom\nMultiple R-squared:  0.8367,    Adjusted R-squared:  0.8334 \nF-statistic: 249.4 on 3 and 146 DF,  p-value: &lt; 2.2e-16\n\n# Now add the interaction term.  These two models are the same.\nmodel3 &lt;- lm( Sepal.Length ~ Species + Petal.Length + Species:Petal.Length, data=iris)\nmodel3 &lt;- lm( Sepal.Length ~ Species * Petal.Length, data=iris)\nsummary(model3)\n\n\nCall:\nlm(formula = Sepal.Length ~ Species * Petal.Length, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.73479 -0.22785 -0.03132  0.24375  0.93608 \n\nCoefficients:\n                               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                      4.2132     0.4074  10.341  &lt; 2e-16 ***\nSpeciesversicolor               -1.8056     0.5984  -3.017  0.00302 ** \nSpeciesvirginica                -3.1535     0.6341  -4.973 1.85e-06 ***\nPetal.Length                     0.5423     0.2768   1.959  0.05200 .  \nSpeciesversicolor:Petal.Length   0.2860     0.2951   0.969  0.33405    \nSpeciesvirginica:Petal.Length    0.4534     0.2901   1.563  0.12029    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3365 on 144 degrees of freedom\nMultiple R-squared:  0.8405,    Adjusted R-squared:  0.8349 \nF-statistic: 151.7 on 5 and 144 DF,  p-value: &lt; 2.2e-16\n\n\nWe can use augment from the broom package to add predicted values to our dataset, with confidence intervals.\n\n# look carefully at the output from here:\nlibrary(broom)\n\nWarning: package 'broom' was built under R version 4.2.3\n\nmodel3 |&gt; augment(interval=\"confidence\")\n\n# A tibble: 150 × 11\n   Sepal.Length Species Petal.Length .fitted .lower .upper  .resid   .hat .sigma\n          &lt;dbl&gt; &lt;fct&gt;          &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1          5.1 setosa           1.4    4.97   4.87   5.07  0.128  0.0226  0.337\n 2          4.9 setosa           1.4    4.97   4.87   5.07 -0.0724 0.0226  0.338\n 3          4.7 setosa           1.3    4.92   4.79   5.05 -0.218  0.0378  0.337\n 4          4.6 setosa           1.5    5.03   4.93   5.12 -0.427  0.0210  0.336\n 5          5   setosa           1.4    4.97   4.87   5.07  0.0276 0.0226  0.338\n 6          5.4 setosa           1.7    5.14   4.97   5.30  0.265  0.0583  0.337\n 7          4.6 setosa           1.4    4.97   4.87   5.07 -0.372  0.0226  0.336\n 8          5   setosa           1.5    5.03   4.93   5.12 -0.0266 0.0210  0.338\n 9          4.4 setosa           1.4    4.97   4.87   5.07 -0.572  0.0226  0.334\n10          4.9 setosa           1.5    5.03   4.93   5.12 -0.127  0.0210  0.337\n# ℹ 140 more rows\n# ℹ 2 more variables: .cooksd &lt;dbl&gt;, .std.resid &lt;dbl&gt;\n\n\nFinally we can use ggplot to show these predicted values and confidence intervals. Take care to understand how the output from each function (ie lm, augment) is piped into the next.\n\nlm( Sepal.Length ~ Species * Petal.Length, data=iris) |&gt;\n  augment(interval=\"confidence\") |&gt; \n  ggplot() + \n    aes(x=Petal.Length, y=Sepal.Length, color=Species) + \n    geom_ribbon(aes(y=.fitted,ymin=.lower, ymax=.upper), alpha=0.1) + \n    geom_point() + \n    geom_line(aes(y=.fitted),lwd=1) + \n    theme_bw()\n\n\n\n# Try changing the forumula to `Sepal.Length ~ Species + Petal.Length`\n# Which model has the better fit? (you can use anova(model2, model3) to compare models)"
  },
  {
    "objectID": "day1.html#character-strings",
    "href": "day1.html#character-strings",
    "title": "Introduction to ‘R’ for statistical analysis",
    "section": "9.1 Character strings",
    "text": "9.1 Character strings\nCharacter strings represent text rather than numbers. Strings are used to label categories in a dataset, to identify columns in a dataset, to make your outputs more readable. You also might find that part of your data has been entered as a string, for example patient identifiers or gene names in a database, or responses to open ended questions.\nStrings are identified in R (and in most other programming languages) by enclosing them in quotes. Single quotes and double quotes can be used (and are treated almost identically), but double quotes are preferred. For example try:\n\nprint(\"Hello\")\n\nprint('Hello')\n\n# What happens here?\nprint(Hello)\n\nA common mistake in R is to forget to enclose strings in quotes. In which case R tries to interpret your input as an object name, leading to an error message if that name doesn’t exist."
  },
  {
    "objectID": "day1.html#logicals",
    "href": "day1.html#logicals",
    "title": "Introduction to ‘R’ for statistical analysis",
    "section": "9.2 Logicals",
    "text": "9.2 Logicals\nLogicals represent binary information in the form TRUE or FALSE. They most often arise as the result of a comparison, for example try:\n\n3&gt;2\n\n\"Hello\" == \"hello\"  # note the double equals sign, this distinguishes assignment from comparison"
  },
  {
    "objectID": "day1.html#converting-between-types",
    "href": "day1.html#converting-between-types",
    "title": "Introduction to ‘R’ for statistical analysis",
    "section": "9.3 Converting between types",
    "text": "9.3 Converting between types\nSometimes it is possible to convert an object from one class to another. For example, a number might be stored as a character string in your data, and you will need to convert it into a numeric before you can do any analysis with it. For example:\n\nx &lt;- \"3\"\nx*2 # What is the error message here?  What does it mean?\n\ny &lt;- as.numeric(x)\ny*2"
  },
  {
    "objectID": "day1.html#missing-elements-in-vectors",
    "href": "day1.html#missing-elements-in-vectors",
    "title": "Introduction to ‘R’ for statistical analysis",
    "section": "9.4 Missing elements in vectors",
    "text": "9.4 Missing elements in vectors\nOften your data will include missing values. R uses NA to represent missing values. For example the following creates a vector (a single variable, like a single column of a data frame) with a missing value in the fourth position:\n\nweights &lt;- c(10,21,32,NA,14)\nweights\n\n\n\n\n\n\n\nWarning\n\n\n\nNote the difference between NA (a missing value) and \"NA\" (a character string containing the letters N and A. I have been tripped up by this a few times when \"NA\" has been entered into a dataset.)"
  },
  {
    "objectID": "day1.html#exercise-1.-effect-of-missing-values",
    "href": "day1.html#exercise-1.-effect-of-missing-values",
    "title": "Introduction to ‘R’ for statistical analysis",
    "section": "9.5 Exercise 1. Effect of missing values",
    "text": "9.5 Exercise 1. Effect of missing values\nTry some other functions with myvector to see what impact the missing data point has.\n\nclass(weights)\n\nplot(weights)\n\nweights&gt;20\n\nmean(weights) # what happens here?  Why?  Can you fix it?\n\nis.na(weights) # what does this do?\n\nsum(is.na(weights)) # can you explain what this does?"
  },
  {
    "objectID": "day1.html#a-continuous-variable-stratified-by-a-grouping-variable-and-the-formula-interface",
    "href": "day1.html#a-continuous-variable-stratified-by-a-grouping-variable-and-the-formula-interface",
    "title": "Introduction to ‘R’ for statistical analysis",
    "section": "10.1 A continuous variable stratified by a grouping variable, and the formula interface",
    "text": "10.1 A continuous variable stratified by a grouping variable, and the formula interface\nWe already saw a way to get means over a categorical variable with Tidyverse:\n\nlibrary(tidyverse)\niris |&gt; group_by(Species) |&gt; summarise(mean(Sepal.Length))\n\nIf we want more than one summary statistic for example, it’s easy with tidyverse (this is an example of a task that is difficult with base R):\n\niris |&gt; group_by(Species) |&gt; summarise(n(),mean(Sepal.Length),sd(Sepal.Length))\n\nWhile dplyr is good for making summary statistics, but to make publication ready tables you can explore the gtsummary package.\nhttps://www.danieldsjoberg.com/gtsummary/articles/tbl_summary.html\n\nlibrary(gtsummary)\n\nWarning: package 'gtsummary' was built under R version 4.2.3\n\n\n#BlackLivesMatter\n\niris |&gt; tbl_summary( by=Species )\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      setosa, N = 501\n      versicolor, N = 501\n      virginica, N = 501\n    \n  \n  \n    Sepal.Length\n5.00 (4.80, 5.20)\n5.90 (5.60, 6.30)\n6.50 (6.23, 6.90)\n    Sepal.Width\n3.40 (3.20, 3.68)\n2.80 (2.53, 3.00)\n3.00 (2.80, 3.18)\n    Petal.Length\n1.50 (1.40, 1.58)\n4.35 (4.00, 4.60)\n5.55 (5.10, 5.88)\n    Petal.Width\n0.20 (0.20, 0.30)\n1.30 (1.20, 1.50)\n2.00 (1.80, 2.30)\n  \n  \n  \n    \n      1 Median (IQR)"
  },
  {
    "objectID": "day1.html#recoding-a-variable-into-groups",
    "href": "day1.html#recoding-a-variable-into-groups",
    "title": "Introduction to ‘R’ for statistical analysis",
    "section": "10.2 Recoding a variable into groups",
    "text": "10.2 Recoding a variable into groups\nSuppose we want to classify flowers into three groups based on their petal length. We need to add another categorical variable to the dataset.\nWhat class should that new variable be?\nBase R has the function cut that divides continuous variables into groups. Tidyverse has a few extensions of this (weirdly in the ggplot2 package), including cut_number that can divide up a continuous variable into three equal groups, and allow us to add labels to them.\n\ncut_number(iris$Petal.Length, 3, labels=c(\"Short\", \"Medium\", \"Long\") )\n\n\n# Using tidyverse to create this variable and add it to the dataset:\nlibrary(ggplot2)\n\niris &lt;- iris |&gt; mutate(PetalLengthGrouped = cut_number(Petal.Length, 3, labels=c(\"Short\", \"Medium\", \"Long\") ))"
  },
  {
    "objectID": "day1.html#tabulating-a-categorical-variable-over-groups",
    "href": "day1.html#tabulating-a-categorical-variable-over-groups",
    "title": "Introduction to ‘R’ for statistical analysis",
    "section": "10.3 Tabulating a categorical variable over groups",
    "text": "10.3 Tabulating a categorical variable over groups\nFor a categorical variable, a summary of frequency counts might be the most appropriate descriptive statistic. We can get this with the table() function. Suppose we wanted to know the distribution of species in our dataset.\n\ntable(iris$Species)\n\nThe ‘table’ function can also generate cross-tabs, by specifying two or three variables.\n\ntable(iris$Species, iris$PetalLengthGrouped) # Base R version\n\niris |&gt; janitor::tabyl(Species, PetalLengthGrouped)  #  The tidyverse version using `tabyl` from the `janitor` package.\niris |&gt; group_by(Species, PetalLengthGrouped) |&gt; tally()\n\nTables of counts are useful, but it might be more helpful to see the proportion of healthy trees by species. To get this we can pass the table we just made into the prop.table() function:\n\ntable1 &lt;- table(iris$Species, iris$PetalLengthGrouped)\nprop.table(table1)\n\n            \n                  Short     Medium       Long\n  setosa     0.33333333 0.00000000 0.00000000\n  versicolor 0.00000000 0.32000000 0.01333333\n  virginica  0.00000000 0.04000000 0.29333333\n\n\nThis is where pipes might be more intuitive:\n\ntable(iris$Species, iris$PetalLengthGrouped) |&gt; prop.table()\n\nThe table above has calculated the ‘cell proportions’. If we want the row percentages we need to set the margin option in prop.table() appropriately. margin=1 is the rows, margin=2 is the columns. If you left out margins altogether, you’d get the cell proportions.\nWe could round this (or any numeric) to 2 d.p. by passing the resulting proportion table into the round() function. and using the function multiply_by from the magrittr package (installed as part of tidyverse) we can turn our proportions into percentages:\n\nlibrary(magrittr)\n\n\nAttaching package: 'magrittr'\n\n\nThe following object is masked from 'package:purrr':\n\n    set_names\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\ntable(iris$Species, iris$PetalLengthGrouped) |&gt; \n  prop.table(margin=1) |&gt; \n  multiply_by(100) |&gt; \n  round(digits=2)\n\n            \n             Short Medium Long\n  setosa       100      0    0\n  versicolor     0     96    4\n  virginica      0     12   88\n\n\nYou might decide that using a function like gtsummary::tbl_summary() is easier!"
  },
  {
    "objectID": "day2.html",
    "href": "day2.html",
    "title": "Intro to R for statistics, Day 2",
    "section": "",
    "text": "Today’s worksheet introduces you to a real dataset.\nThe tasks you will cover are:"
  },
  {
    "objectID": "day2.html#the-dataset",
    "href": "day2.html#the-dataset",
    "title": "Intro to R for statistics, Day 2",
    "section": "The dataset",
    "text": "The dataset\nThe data are from a randomised clinical trial of a new rehabilition intervention (compared to standard post-stroke care) aimed at improving the walking speed of hospital patients. Better walking speed is a good indicator of general stroke recovery.\nWe have recorded:\n\nThe age and sex of each participant,\nThe treatment allocation,\nThe hospital department from which they were recruited and\nTime they take to complete a walking task.\n\nOur research questions are:\n\nDoes the treatment improve walking speed compared to controls?\nBy how much does it improve, and how certain are we of this?\n\nThe dataset can be found at walkingspeed_day2.xlsx\n\nPowerpoint slides to support this material are at:\n\nday3.pptx\nday3_data_lm.pptx"
  },
  {
    "objectID": "day2.html#make-sure-the-data-looks-ok-and-is-in-the-right-place-on-your-computer",
    "href": "day2.html#make-sure-the-data-looks-ok-and-is-in-the-right-place-on-your-computer",
    "title": "Intro to R for statistics, Day 2",
    "section": "Make sure the data looks OK and is in the right place on your computer",
    "text": "Make sure the data looks OK and is in the right place on your computer\nBefore we dive in and import it, we need to make sure our data is in a sensible place.\n\nOpen RStudio and switch to the project you created in day 1, or start a new project if necessary.\nThen, save the example data walkingspeed_day2.xlsx for this tutorial into your project folder. Check that it has appeared in the ‘files’ pane in RStudio.\nStart a new script file that will eventually include all of the commands we need to import, clean, visualise and analyse the data.\nNow open the dataset in Excel and explore the file so that you understand what is there."
  },
  {
    "objectID": "day2.html#read-the-help",
    "href": "day2.html#read-the-help",
    "title": "Intro to R for statistics, Day 2",
    "section": "Read the help!",
    "text": "Read the help!\nWe are nearly ready to import our data. But before using a new function its always good to read its documentation.\nR and R packages are not as self-explanatory as other software, and so you should expect to spend a fair amount of time, particularly as you are learning R, reading documentation, vignettes, blogs, etc on what R can do, which packages exist, and how to use them.\nThe read_excel() function has a few different options so first we should look at the help file:\n\n?read_excel # where does the helpfile appear?\n\nMake sure to check:\n\nDescription what does the function do,\nUsage what is the syntax\nArguments detail of what all the options mean\nValue what do I get when I run this\nExamples (usually very helpful)\n\nNote from the help file that read_excel() can extract data from different sheets and ranges of an Excel workbook, can use or ignore column names, and allows you to specify the type of data (numeric, dates, text etc) if you want to, or leave it to R to guess.\nMany R packages also have vignettes or websites including simpler guides to their use in specific cases. readxl has a website that you might find helpful: https://readxl.tidyverse.org/\nNow we’ll load the data. We want to use the ‘walking speed’ data from the walkingspeed.xlsx spreadsheet.\n\nOpen the spreadsheet in Excel and find this sheet. The data we want is in the sheet called ‘day2’.\n\nFrom the read_excel() help file we can deduce the syntax to load this data into R:\n\nlibrary(readxl)\n\nWarning: package 'readxl' was built under R version 4.2.2\n\nwalkingdat &lt;- read_excel(path=\"walkingspeed_day2.xlsx\", sheet=\"day2\")\n\nThis line assumes that the file ‘walkingspeed_day2.xlsx’ is in the current working directory (you can check what this is with getwd(). The current working directory is shown just above the R console window. You can see the files in the current working directory in the ‘Files’ tab on the bottom right of the RStudio window. When you create or load a project RStudio will set the working directory to the root of the project directory.\nThis line calls the read_excel() function, with the arguments ‘path’, ‘sheet’ set. The other arguments will be set to their default values, which you can see from the help file.\nWe could have set the range of the data in the spreadsheet (I usually do this for safety), but read_excel() can figure it out automatically most of the time; by default it picks the biggest continuous chunk of data starting in the top left of the sheet.\nNow you should have a ‘data frame’ object called walkingdat in your environment, which includes the data from the Excel sheet ready to process and analyse.\nOur workflow now is:\n\nClean and code\nVisualise\nDescribe\nModel\nDiagnose model\nInterpret"
  },
  {
    "objectID": "day2.html#dealing-with-outliers",
    "href": "day2.html#dealing-with-outliers",
    "title": "Intro to R for statistics, Day 2",
    "section": "Dealing with outliers",
    "text": "Dealing with outliers\nIt looks like there are some unreasonably high and low values of walking time.\nWe can make another graph of walking speed against age, this time on a logarithmic scale so both the extreme high and extreme low points are visible, to see what is going on.\n\n## ggplot2 version\nlibrary(ggplot2)\nggplot(walkingdat) + aes(x=age, y=time) + geom_point() + scale_y_log10()\n\nWarning: Transformation introduced infinite values in continuous y-axis\n\n\nWarning: Removed 1 rows containing missing values (`geom_point()`).\n\n\n\n\n## base R version\nplot(walkingdat$age, walkingdat$time, log=\"y\")\n\nWarning in xy.coords(x, y, xlabel, ylabel, log): 1 y value &lt;= 0 omitted from\nlogarithmic plot\n\n\n\n\n\nIt seems there are some values for time that are likely to be technical errors. We can remove these values (set them to missing) in a few different ways:\n\n## base R method\nwalkingdat$time[walkingdat$time&lt;0.1] &lt;- NA\nwalkingdat$time[walkingdat$time&gt;100] &lt;- NA\n\n## Using mutate and ifelse\nwalkingdat &lt;- walkingdat |&gt; mutate(time = ifelse(time&lt;0.1,NA,time))\nwalkingdat &lt;- walkingdat |&gt; mutate(time = ifelse(time&gt;100,NA,time))\n\n## the 'pure' tidyverse way with case_when is a bit clunky.\n## look up 'case_when()' to understand this line\nwalkingdat &lt;- walkingdat |&gt; mutate( time = case_when(time&lt;0.1 ~ NA_real_ , \n                                                     time&gt;100 ~ NA_real_, \n                                                     TRUE ~ time) )\n\n# Now check the distribution of time again.\nhist(walkingdat$time, breaks=100)\n\n\n\nrange(walkingdat$time, na.rm = TRUE)\n\n[1]  1.435 17.641\n\n\nNow we have a cleaned dataset in our environment we can proceed with our visualisation and analysis:"
  },
  {
    "objectID": "day2MSc.html",
    "href": "day2MSc.html",
    "title": "Intro to R for statistics, Day 2 (MSc version)",
    "section": "",
    "text": "Today’s worksheet introduces you to a real dataset.\nThe tasks you will cover are:"
  },
  {
    "objectID": "day2MSc.html#the-dataset",
    "href": "day2MSc.html#the-dataset",
    "title": "Intro to R for statistics, Day 2 (MSc version)",
    "section": "The dataset",
    "text": "The dataset\nThe data are from a randomised clinical trial of a new rehabilition intervention (compared to standard post-stroke care) aimed at improving the walking speed of hospital patients. Better walking speed is a good indicator of general stroke recovery.\nWe have recorded:\n\nThe age and sex of each participant,\nThe treatment allocation,\nThe hospital department from which they were recruited and\nTime they take to complete a walking task.\n\nOur research questions are:\n\nDoes the treatment improve walking speed compared to controls?\nBy how much does it improve, and how certain are we of this?\n\nThe dataset can be found at walkingspeed_day2.xlsx\n\nPowerpoint slides to support this material are at:\n\nday3.pptx\nOur workflow is:\n\nClean and code\nVisualise\nDescribe\nModel\nDiagnose model\nInterpret"
  },
  {
    "objectID": "day2MSc.html#make-sure-the-data-looks-ok-and-is-in-the-right-place-on-your-computer",
    "href": "day2MSc.html#make-sure-the-data-looks-ok-and-is-in-the-right-place-on-your-computer",
    "title": "Intro to R for statistics, Day 2 (MSc version)",
    "section": "Make sure the data looks OK and is in the right place on your computer",
    "text": "Make sure the data looks OK and is in the right place on your computer\nBefore we dive in and import it, we need to make sure our data is in a sensible place.\n\nOpen RStudio and open the project you created in day 1 (if not already opened).\nThen, save the example data walkingspeed_msc.xlsx for this tutorial into your project folder. Check that it has appeared in the ‘files’ pane in RStudio.\nStart a new script file that will eventually include all of the commands we need to import, clean, visualise and analyse the data.\nNow open the dataset in Excel and explore the file so that you understand what is there."
  },
  {
    "objectID": "day2MSc.html#read-the-help",
    "href": "day2MSc.html#read-the-help",
    "title": "Intro to R for statistics, Day 2 (MSc version)",
    "section": "Read the help!",
    "text": "Read the help!\nWe are nearly ready to import our data. But remember that before using a new function its always good to read its documentation. The read_excel() function has a few different options so first we should look at the help file:\n\n?read_excel\n\nNote from the help file that read_excel() can extract data from different sheets and ranges of an Excel workbook, can use or ignore column names, and allows you to specify the type of data (numeric, dates, text etc) if you want to, or leave it to R to guess.\nMany R packages also have vignettes or websites including simpler guides to their use in specific cases. readxl has a website that you might find helpful: https://readxl.tidyverse.org/\nNow we’ll load the data. We want to use the ‘walking speed’ data from the walkingspeed_msc.xlsx spreadsheet.\n\nOpen the spreadsheet in Excel and find this sheet. The data we want is in the sheet called ‘day2’.\n\nFrom the read_excel() help file we can deduce the syntax to load this data into R:\n\nlibrary(readxl)\n\nWarning: package 'readxl' was built under R version 4.2.2\n\nwalkingdat &lt;- read_excel(path=\"walkingspeed_msc.xlsx\", sheet=\"day2\")\n\nThis line assumes that the file walkingspeed_msc.xlsx is in the current working directory (you can check what this is with getwd()). The current working directory is shown just above the R console window. You can see the files in the current working directory in the ‘Files’ tab on the bottom right of the RStudio window. When you create or load a project RStudio will set the working directory to the root of the project directory.\nThis line calls the read_excel() function, with the arguments path, sheet set. The other arguments will be set to their default values, which you can see from the help file.\nWe could have set the range of the data in the spreadsheet (I usually do this for safety), but read_excel() can figure it out automatically most of the time; by default it picks the biggest continuous chunk of data starting in the top left of the sheet.\nNow you should have a ‘data frame’ object called walkingdat in your environment, which includes the data from the Excel sheet ready to process and analyse."
  },
  {
    "objectID": "day2MSc.html#dealing-with-outliers",
    "href": "day2MSc.html#dealing-with-outliers",
    "title": "Intro to R for statistics, Day 2 (MSc version)",
    "section": "Dealing with outliers",
    "text": "Dealing with outliers\nIt looks like there are some unreasonably high and low values of walking time.\nWe can make another graph of walking speed against age, this time on a logarithmic scale so both the extreme high and extreme low points are visible, to see what is going on.\n\n## base R version\nplot(walkingdat$age, walkingdat$time, log=\"y\")\n\nWarning in xy.coords(x, y, xlabel, ylabel, log): 1 y value &lt;= 0 omitted from\nlogarithmic plot\n\n\n\n\n## ggplot2 version\nlibrary(ggplot2)\nggplot(data = walkingdat) + aes(x=age, y=time) + geom_point() + scale_y_log10()\n\nWarning: Transformation introduced infinite values in continuous y-axis\n\n\nWarning: Removed 1 rows containing missing values (`geom_point()`).\n\n\n\n\n\nIt seems there are some values for time that are likely to be technical errors. We can remove these values (set them to missing) in a few different ways:\n\n## base R method to replace the values with NA ('missing')\nwalkingdat$time[walkingdat$time&lt;0.1] &lt;- NA\nwalkingdat$time[walkingdat$time&gt;100] &lt;- NA\n\n## Using filter we could remove those datapoints\nwalkingdat &lt;- walkingdat |&gt; filter(time &lt; 100) |&gt; filter(time &gt; 0.1)\n\n\n# Now check the distribution of time again.\nhist(walkingdat$time, breaks=100)\n\n\n\nrange(walkingdat$time, na.rm = TRUE)\n\n[1]  1.435 17.641\n\n\nNow we have a cleaned dataset in our environment we can proceed with our visualisation and analysis:"
  },
  {
    "objectID": "day2MSc.html#graphics",
    "href": "day2MSc.html#graphics",
    "title": "Intro to R for statistics, Day 2 (MSc version)",
    "section": "Graphics",
    "text": "Graphics\n\nGraphing\n\nConsider what kind of graph you might make to illustrate the difference in walking speed between treatment groups, and try to make it using ggplot. Eg:\nMake a box plot of time by sex, with a different coloured box per sex\nLabel the axes appropriately\nTry a violin plot instead of a boxplot (with geom_violin). Which do you prefer?\nMake any other adjustments you think are informative!"
  },
  {
    "objectID": "day2MSc.html#modelling",
    "href": "day2MSc.html#modelling",
    "title": "Intro to R for statistics, Day 2 (MSc version)",
    "section": "Modelling",
    "text": "Modelling\nI have left these sections in from the PhD workshop. Attempt them if you get time.\n\nHypothesis Testing\n\nWhat is the difference in average walking speed between control patients and treated patients?\nIs this difference statistically significant? Use t-test t.test() and Mann-Whitney tests wilcox.test() to examine the differences between the groups. Look up the syntax for t.test() and wilcox.test() using the help system, and use them to check whether the time taken to complete the task varies by treatment status. In each case use the version of the function that takes a formula agument. Remember the formula syntax from the boxplot and lm functions in day 1.\nCompare the p-values for each method.\nConsider the assumptions for a t-test, and whether they are met in this dataset.\n\nDo you believe that treatment affects walking speed?\n\nLinear model diagnostics\n\nEstimate a linear model (with lm) to estimate/test the effect of treatment on task completion time.\nUse summary to get the model coefficients and p-values\nUse broom::tidy to get the model coefficients and p-values\nCompare the model results to the equivalent t-test\nExtend the model to include the effects of age and sex as potential covariates.\nUse plot() to explore the model diagnostics\nUse performance::check_model() to explore the model diagnostics\nNow estimate a new model to compare the task completion speed between groups.\nGet the model coefficients and p-values\nCheck the model diagnostics using plot or performance::check_model\nWhy are the result from this model different? How do you interpret the results?\nCan you get the confidence intervals for the treatment effect (use the help for broom::tidy)\nUse model_summary package to make a pretty model summary table"
  },
  {
    "objectID": "day3.html",
    "href": "day3.html",
    "title": "Intro to R day 3 - Notes on Graphing",
    "section": "",
    "text": "The dataset to support today’s work is here: walkingspeed.xlsx:\nPowerpoint slides are here: day3.pptx\nAn explanation/breakdown of the code for a typical ggplot2 graph is here: flipbook.html\nPlotting data is an essential part of data analysis and reporting. Your plots communicate your results, and a good plot can be the difference between a successful and unsuccessful communication.\nIn this session we’ll think about how to plot your data, what makes a good vs a bad plot, and illustrate some concepts for plotting using R.\nLearning objectives:"
  },
  {
    "objectID": "day3.html#descriptive-plots",
    "href": "day3.html#descriptive-plots",
    "title": "Intro to R day 3 - Notes on Graphing",
    "section": "Descriptive plots",
    "text": "Descriptive plots\nBefore we model data we should visualise it. This crucial first step is often omitted in analyses and reports. Consider the follow example, that I have designed after a real analysis I worked on earlier this year, where an outcome was compared between two treatment conditions:\n\nlibrary(ggplot2)\nlibrary(ggpubr)\nset.seed(12345) # Set seed is used to ensure that 'random' samples will come out the same each time.\nN=12\ny &lt;- c(runif(N), c(runif(N-2), 4.5,6))\nx &lt;- factor(rep(c(1,2), each=N))\nggplot(data.frame(Group=x,y), aes(x,y)) + \n  stat_summary(geom=\"col\",width=0.5, fill=\"red\") + \n  stat_summary(geom=\"errorbar\", width=0.2) + \n  theme_bw()+ stat_compare_means(label.y = 2)\n\n\n\n\nOn the face of it, it looks like the outcome is higher in group 2 than group 1. If this is all you see then this is surely the conclusion you would come to.\nBut why is the p-value so high? And how well do you feel like you understand the data from this graph?\nConsider now how you would interpret this:\n\nlibrary(ggplot2)\nggplot(data.frame(Group=x,y), aes(x,y)) + \n  geom_point() + \n  theme_bw()\n\n\n\n\nQuite differently? At least with this second visualisation we can see the data and draw our conclusions about what is going on directly.\nAlso consider, the first graph only shows you four values, two means and two standard errors (if that is what they are, I never actually told you). It’s a complete waste of ink. But how often do you see this first presentation in the scientific papers your read? When I see one of these I can’t help but wonder what horrors it is hiding.\nThe second graph tells us quite a lot. It tells us to maybe check our outlying data points, or to try transforming our data before analysis. We might even conclude that the two groups are more-or-less the same, except for two individuals, which may well be a real effect of treatment that is limited to specific individuals. In any case we learn a lot.\nSo our most important rule is: always plot your data, and not summaries of the data.\nIdeally, if we have a dataset with several variables, we will make something like a graph matrix showing every variable against every other variable. This will help us identify any potential problems or outliers in 2-dimensions.\nThe ggpairs function in the GGally package gives us a grid layout showing all of these combinations. I think its a reasonable summary.\n\nlibrary(readxl)\nlibrary(GGally)\nwalkingdata &lt;- read_excel(path=\"walkingspeed.xlsx\", sheet=\"fixed\")\nwalkingdata$department &lt;- factor(walkingdata$department)\nwalkingdata$time &lt;- as.numeric(walkingdata$time)\nwalkingdata$time[walkingdata$time&gt;100] &lt;- NA\nwalkingdata$time[walkingdata$time&lt;1] &lt;- NA\nggpairs(walkingdata, columns=1:6)\n\n\n\n\nNote I’m not wasting a lot of time making this graph pretty. It’s for me only, I don’t care what it looks like, I just want to see the data as quickly and as effectively as possible. I’ve also left patient ID in here as a variable, there’s no harm doing this, and it might show me if any data errors have occurred.\nDoes this graph meet all of the objectives that we set out for our ‘descriptive’ analyses above?"
  },
  {
    "objectID": "day3.html#inferential-graphs",
    "href": "day3.html#inferential-graphs",
    "title": "Intro to R day 3 - Notes on Graphing",
    "section": "Inferential graphs",
    "text": "Inferential graphs\nWhile the descriptive graphs tells us about the data, it doesn’t tell us much about the comparison we are interested in making.\nTo think about how we could graph that, first think about what exactly it is we are trying to show.\nLets go back to our linear model from last time:\n\nmodel1 &lt;- lm(data=walkingdata, log(time) ~ group + sex + age + factor(department))\nsummary(model1)\n\n\nCall:\nlm(formula = log(time) ~ group + sex + age + factor(department), \n    data = walkingdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.66614 -0.17268 -0.02574  0.09920  1.76808 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)          0.180866   0.343877   0.526  0.59985   \ngrouptreat          -0.184903   0.059587  -3.103  0.00237 **\nsexM                 0.038621   0.072702   0.531  0.59620   \nage                  0.014986   0.006238   2.402  0.01777 * \nfactor(department)2  0.108484   0.088572   1.225  0.22295   \nfactor(department)3 -0.097133   0.084065  -1.155  0.25011   \nfactor(department)4 -0.057919   0.087749  -0.660  0.51044   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3378 on 125 degrees of freedom\n  (3 observations deleted due to missingness)\nMultiple R-squared:  0.1723,    Adjusted R-squared:  0.1325 \nF-statistic: 4.336 on 6 and 125 DF,  p-value: 0.0005211\n\n\nWhat is the key information here that we need to communicate?\nWe should say what our estimate of the treatment effect is, and how sure we are of this. That is the ‘actionable’ result from this work, and that is what we want people to take away from our analysis. The fact of the treatments being ‘significantly’ different is interesting but not enough on its own. So from our analysis we should be trying to communicate the estimate of treatment effect, the standard error of treatment effect, and potentially the p-value and a confidence interval for the difference.\nThe mean time in each group is perhaps interesting descriptively, so people can understand our sample. It’s hard to see why the standard error within each group should be of interest.\nSo - do I even need a graph? Should this summary statistic, mean difference = 0.19 (standard error=0.06; p=0.0015) be enough? Recall that this was calculated on a logarithmic scale, so it’s probably best to exponentiate it and report a ratio:\n\nlibrary(emmeans)\nem1 &lt;- emmeans(model1, \n               trt.vs.ctrl~group, \n               type=\"response\")$contrast\nconfint(em1)\n\n contrast        ratio     SE  df lower.CL upper.CL\n treat / control 0.831 0.0495 125    0.739    0.935\n\nResults are averaged over the levels of: sex, department \nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \n\n\nSo we could say “times for treated group were 83% of the times for the control group (95% CI=74% to 93%)”. Or: “treatment improved times by 17% (95% CI=7-26%).”\nIs this enough? I think so, if combined with a visual summary that persuades us that the model is reasonable, and we have the descriptive graph that shows us this difference in the context of the variance in the data.\nCompare this with the traditional presentation:\n\nlibrary(ggpubr) # includes the stat_compare_means function\nggplot(walkingdata, aes(x=group, y=time)) + \n  stat_summary(geom=\"col\", width=0.5, fill=\"red\") + \n  stat_summary(geom=\"errorbar\", width=.2) + \n  scale_x_discrete(na.translate=FALSE) + \n  theme_bw() + \n  stat_compare_means()\n\n\n\n\nor better, but still not so informative:\n\nlibrary(ggpubr)\nlibrary(ggbeeswarm)\nggplot(remove_missing(walkingdata), aes(x=group, y=time)) + \n  geom_beeswarm(col=\"grey\") + \n  stat_summary(geom=\"errorbar\", width=.2) + \n  stat_summary(geom=\"point\", width=.2) + \n  theme_bw()+ scale_y_log10() + \n  stat_compare_means(method=\"t.test\",\n                     label = \"p.signif\",\n                     comparisons=list(c(\"treated\", \"control\")))\n\n\n\n\nCould you say what the treatment effect is by looking at this graph? How sure would you be about it? Also, how would you represent a model other than a simple comparison of means (for example, the multiple linear regression model that we estimated). By confusing the descriptive with the inferential graph we are limiting our ability to conduct the appropriate statistical analysis.\nSuppose we wanted to compare several groups, say time over department, then a visualisation might be useful:\n\nlibrary(emmeans)\nlibrary(broom)\nem2 &lt;- emmeans(model1, \n               trt.vs.ctrl~department, \n               type=\"response\")$contrast\ntd &lt;- tidy(em2, conf.int = TRUE)\ntd\n\n# A tibble: 3 × 11\n  term       contrast  null.value ratio std.error    df conf.low conf.high  null\n  &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 department departme…          0 1.11     0.0987   125    0.902      1.38     1\n2 department departme…          0 0.907    0.0763   125    0.742      1.11     1\n3 department departme…          0 0.944    0.0828   125    0.765      1.16     1\n# ℹ 2 more variables: statistic &lt;dbl&gt;, adj.p.value &lt;dbl&gt;\n\nggplot(td) + \n  aes(x=contrast, y=ratio, ymax=conf.high, ymin=conf.low) + \n  geom_pointrange() + \n  coord_flip() + \n  geom_hline(yintercept=1) + theme_bw()"
  },
  {
    "objectID": "dichot.html",
    "href": "dichot.html",
    "title": "Why is ‘grouping’ your samples bad for analysis?",
    "section": "",
    "text": "Summary\nIf we have continuous data then we should keep it continuous in analysis. Grouping samples into (say) ‘high’ vs ‘low’ or ‘recovered’ vs ‘not recovered’ throws away information and makes it more difficult to detect associations. The power of your study is reduced and the sample size needed goes up.\n\n\nMotivation\nSuppose we are interested in the effect of an exposure on an outcome, and we have measured both in a sample. Both our exposure and our outcome are measured as continuous variables, for example we might be interested in the effect of fibre intake on gut microbial diversity.\nThere are a couple of possible approaches to the analysis. First, we could estimate or test for a correlation between the exposure and the outcome.\nAlternatively we could dichotomise the exposure, splitting the samples into a “high fibre” and a “low fibre” group, before comparing the microbial diversity in each group. Or we could dichotomise the outcome into “high diversity” and “low diversity”.\nWhich should we choose? Intuitively we might prefer the dichotomised version for “ease of interpretation”, but how does it affect our ability to detect any association?\n\n\nPackages\nWe’ll need the following R packages for this simulation:\n\nlibrary(pwr)\nlibrary(rmarkdown)\nlibrary(knitr)\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(MASS)\nlibrary(data.table)\n\n\n\nDataset\nSuppose our exposure and outcome are both normally distributed with a correlation of 0.5.\nWe can sample 50 points as follows:\n\nset.seed(21)\ndat = data.frame(mvrnorm(n=30, mu=c(10,10), Sigma = matrix(c(1,0.5,0.5,1),nrow=2)))\nnames(dat) &lt;- c(\"Exposure\", \"Outcome\")\n\nggplot(dat, aes(x=Exposure, y=Outcome)) + geom_point() + theme_bw()\n\n\n\n\nHow can we estimate or test this correlation by statistical analysis?\nThe simplest way would be to test\n\ncor.test(dat$Exposure, dat$Outcome)\n\n\n    Pearson's product-moment correlation\n\ndata:  dat$Exposure and dat$Outcome\nt = 3.0861, df = 28, p-value = 0.004535\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.1753575 0.7313294\nsample estimates:\n      cor \n0.5037987 \n\n\nSo in our sample this correlation is clearly detectable (estimated r=0.50, p=0.0045).\n\n\nDichotomising variables\nDichotomising means splitting variables into two groups. In our example we might decide to compare those with a high vs a low exposure. Lets make a variable corresponding to whether the exposure for each participant is above observed median. This will split the data into two groups, and we can describe how the outcome differs between the high and low exposure groups:\n\ndat$HighExposure &lt;- dat$Exposure &gt; median(dat$Exposure)\n(ggplot(dat, aes(Exposure, Outcome, color=HighExposure)) + \n  geom_point() + theme_bw() + \n  scale_color_manual(values=c(\"black\", \"red\")))+\n(ggplot(dat, aes(HighExposure, Outcome)) + \n  geom_boxplot() + geom_point(aes(color=HighExposure)) + theme_bw()+ \n  scale_color_manual(values=c(\"black\", \"red\")))\n\n\n\n\nNow we can use (for example) a t-test to for difference in outcome between “high” and “low” exposure groups:\n\nt.test(data=dat, Outcome ~ HighExposure)\n\n\n    Welch Two Sample t-test\n\ndata:  Outcome by HighExposure\nt = -2.3855, df = 27.985, p-value = 0.02407\nalternative hypothesis: true difference in means between group FALSE and group TRUE is not equal to 0\n95 percent confidence interval:\n -1.5826037 -0.1203041\nsample estimates:\nmean in group FALSE  mean in group TRUE \n           9.723858           10.575312 \n\n\nThe difference is now barely detectable (p=0.024)!\nWe could go further, and dichotomise both the outcome and the exposure.\n\ndat$HighOutcome &lt;- dat$Outcome &gt; median(dat$Outcome)\n(ggplot(dat, aes(Exposure, Outcome, color=HighExposure, shape=HighOutcome)) + \n  geom_point() + theme_bw() + geom_hline(yintercept=median(dat$Outcome),lty=2)+\n  scale_color_manual(values=c(\"black\", \"red\")))+\n(ggplot(dat, aes(HighExposure, as.numeric(HighOutcome))) + \n  geom_bar(stat=\"summary\", fun.y=mean, col=\"black\", aes(fill=HighExposure)) + theme_bw()+\n   labs(y=\"Proportion with high outcome\")+\n  scale_fill_manual(values=c(\"black\", \"red\")))\n\n\n\n\nNow our relationship seems obscured. Our analysis consists of analysing a 2x2 contingency table:\n\ntable(dat$HighExposure, dat$HighOutcome)\n\n       \n        FALSE TRUE\n  FALSE    10    5\n  TRUE      5   10\n\nchisq.test(table(dat$HighExposure, dat$HighOutcome))\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  table(dat$HighExposure, dat$HighOutcome)\nX-squared = 2.1333, df = 1, p-value = 0.1441\n\n\nThe difference in ‘high outcome’ proportions between exposure groups is not statistically significant! (p=0.14). This shows that it is much more difficult to see the relationship if we throw away the exact values of the data points.\nSo although there is a real relationship between exposure and outcome that we have been able to detect by correlating the values in our sample, it was harder to detect when we dichotomised the exposure, and we could not detect it at all in the grouped data.\n\n\nImplications for power and sample size\nOur single example illustrated that dichotomising data made analysis difficult or impossible by discarding data. But it’s easy to cherry pick examples, how does this work in general?\nWe can quantify the average loss of information by power calculations (repeated simulations), and consider how much our sample size would need to increase to overcome this.\nThe graph below shows the power to detect a correlation of 0.5 as the sample size changes using each of the methods described above.\nIf we analyse the continuous data then we need a sample size of about 28 for a power of 80%. If we dichotomise the exposure only we would need 43 samples, if we dichotomise both and analyse the 2x2 table we would need 69, more than twice the original sample.\n\nsampleSizes &lt;- seq(10,100,5)\n\npowers &lt;- data.table(t(sapply(sampleSizes, function(n){c(\n  sampleSizes=n,\n  continuous=100*pwr.r.test(r=0.5, n = n)$power,\n  dichotone=100*pwr.t.test(d=.8 / 0.91, n = n/2)$power,\n  dichotboth=100*pwr.2p.test(h=ES.h(1/3, 2/3), n = n/2)$power\n  )\n  })))\n\nggplot(melt(powers,id.vars = \"sampleSizes\", variable.name = \"Analysis\", value.name = \"Power\"), \n       aes(sampleSizes, Power, color=Analysis)) + \n  geom_line() + \n  geom_point() + \n  theme_bw() + \n  scale_x_continuous(limits=c(0,100)) + \n  labs(x=\"Sample Size (total)\", y=\"Power (%)\") + \n  scale_color_manual(labels=c(dichotboth=\"Dichotomise both\", \n                              dichotone=\"Dichtomise outcome only\", \n                              continuous=\"Correlate continuous measures\"), \n                     values=c(\"black\", \"red\", \"blue\")) + \n  theme(legend.position = c(0.7,0.3), legend.background = element_rect(linetype = 1, size = .5, colour = \"black\")) + \n  geom_hline(yintercept=80, lty=2)\n\n\n\n\n\n\nConclusion\nGrouping up our continuous variables for analysis throws away information. It makes associations more difficult to detect, and increases the number of samples we need to analyse.\nThere are other harmful consequences to dichotomising data. Sometimes a defense of the practice is that by collapsing quantiative findings into yes/no outcomes makes results easier to interpret, but Stephen Senn makes a good case that this is wrong and can even be misleading.\nSo in general, if the phenomenon you are interested in can be measured continuously then you should do so, and be sure to use all of this quantitative information in the analysis.\n\n\nReferences (todo - tidy this up)\nThis phenomenon has been discussed many times in the statistical literature and in blogs\nhttps://errorstatistics.com/2016/08/02/s-senn-painful-dichotomies-guest-post/ (Senn 2016 - a not identical but related problem with dichtomies)\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC1458573/ (Altman and Royston 2006)\nhttp://www.psychology.sunysb.edu/attachment/measures/content/maccallum_on_dichotomizing.pdf (MacCallum et al 2002)\nhttps://bjo.bmj.com/content/98/6/841 (Cumberland et al 2014)"
  },
  {
    "objectID": "flipbook.html#section",
    "href": "flipbook.html#section",
    "title": "Basic ggplot for scientific graphing",
    "section": "",
    "text": "library(readxl)"
  },
  {
    "objectID": "flipbook.html#section-1",
    "href": "flipbook.html#section-1",
    "title": "Basic ggplot for scientific graphing",
    "section": "",
    "text": "library(readxl)\nwalkingdata &lt;- read_excel(path=\"walkingspeed.xlsx\",\n                          sheet=\"fixed\")"
  },
  {
    "objectID": "flipbook.html#section-2",
    "href": "flipbook.html#section-2",
    "title": "Basic ggplot for scientific graphing",
    "section": "",
    "text": "library(readxl)\nwalkingdata &lt;- read_excel(path=\"walkingspeed.xlsx\",\n                          sheet=\"fixed\")\nwalkingdata$department &lt;- factor(walkingdata$department)"
  },
  {
    "objectID": "flipbook.html#section-3",
    "href": "flipbook.html#section-3",
    "title": "Basic ggplot for scientific graphing",
    "section": "",
    "text": "library(readxl)\nwalkingdata &lt;- read_excel(path=\"walkingspeed.xlsx\",\n                          sheet=\"fixed\")\nwalkingdata$department &lt;- factor(walkingdata$department)\nwalkingdata$time &lt;- as.numeric(walkingdata$time)"
  },
  {
    "objectID": "flipbook.html#section-4",
    "href": "flipbook.html#section-4",
    "title": "Basic ggplot for scientific graphing",
    "section": "",
    "text": "library(readxl)\nwalkingdata &lt;- read_excel(path=\"walkingspeed.xlsx\",\n                          sheet=\"fixed\")\nwalkingdata$department &lt;- factor(walkingdata$department)\nwalkingdata$time &lt;- as.numeric(walkingdata$time)\nwalkingdata$time[walkingdata$time&gt;100] &lt;- NA"
  },
  {
    "objectID": "flipbook.html#section-5",
    "href": "flipbook.html#section-5",
    "title": "Basic ggplot for scientific graphing",
    "section": "",
    "text": "library(readxl)\nwalkingdata &lt;- read_excel(path=\"walkingspeed.xlsx\",\n                          sheet=\"fixed\")\nwalkingdata$department &lt;- factor(walkingdata$department)\nwalkingdata$time &lt;- as.numeric(walkingdata$time)\nwalkingdata$time[walkingdata$time&gt;100] &lt;- NA\nwalkingdata$time[walkingdata$time&lt;1] &lt;- NA"
  },
  {
    "objectID": "flipbook.html#section-6",
    "href": "flipbook.html#section-6",
    "title": "Basic ggplot for scientific graphing",
    "section": "",
    "text": "library(readxl)\nwalkingdata &lt;- read_excel(path=\"walkingspeed.xlsx\",\n                          sheet=\"fixed\")\nwalkingdata$department &lt;- factor(walkingdata$department)\nwalkingdata$time &lt;- as.numeric(walkingdata$time)\nwalkingdata$time[walkingdata$time&gt;100] &lt;- NA\nwalkingdata$time[walkingdata$time&lt;1] &lt;- NA\n\nhead(walkingdata)\n\n\n\n\n# A tibble: 6 × 6\n  patid group    time sex     age department\n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;fct&gt;     \n1     1 treat    1.90 M        53 3         \n2     2 control  3.54 M        61 3         \n3     3 treat    2.93 M        65 1         \n4     4 control  1.82 M        48 2         \n5     5 treat    2.20 M        62 2         \n6     6 control  3.04 M        62 4"
  },
  {
    "objectID": "flipbook.html#section-7",
    "href": "flipbook.html#section-7",
    "title": "Basic ggplot for scientific graphing",
    "section": "",
    "text": "library(readxl)\nwalkingdata &lt;- read_excel(path=\"walkingspeed.xlsx\",\n                          sheet=\"fixed\")\nwalkingdata$department &lt;- factor(walkingdata$department)\nwalkingdata$time &lt;- as.numeric(walkingdata$time)\nwalkingdata$time[walkingdata$time&gt;100] &lt;- NA\nwalkingdata$time[walkingdata$time&lt;1] &lt;- NA\n\nhead(walkingdata)\n\nlibrary(ggplot2)\n\n\n\n\n# A tibble: 6 × 6\n  patid group    time sex     age department\n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;fct&gt;     \n1     1 treat    1.90 M        53 3         \n2     2 control  3.54 M        61 3         \n3     3 treat    2.93 M        65 1         \n4     4 control  1.82 M        48 2         \n5     5 treat    2.20 M        62 2         \n6     6 control  3.04 M        62 4"
  },
  {
    "objectID": "flipbook.html#section-8",
    "href": "flipbook.html#section-8",
    "title": "Basic ggplot for scientific graphing",
    "section": "",
    "text": "library(readxl)\nwalkingdata &lt;- read_excel(path=\"walkingspeed.xlsx\",\n                          sheet=\"fixed\")\nwalkingdata$department &lt;- factor(walkingdata$department)\nwalkingdata$time &lt;- as.numeric(walkingdata$time)\nwalkingdata$time[walkingdata$time&gt;100] &lt;- NA\nwalkingdata$time[walkingdata$time&lt;1] &lt;- NA\n\nhead(walkingdata)\n\nlibrary(ggplot2)\n\nggplot(walkingdata)\n\n\n\n\n# A tibble: 6 × 6\n  patid group    time sex     age department\n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;fct&gt;     \n1     1 treat    1.90 M        53 3         \n2     2 control  3.54 M        61 3         \n3     3 treat    2.93 M        65 1         \n4     4 control  1.82 M        48 2         \n5     5 treat    2.20 M        62 2         \n6     6 control  3.04 M        62 4"
  },
  {
    "objectID": "flipbook.html#section-9",
    "href": "flipbook.html#section-9",
    "title": "Basic ggplot for scientific graphing",
    "section": "",
    "text": "library(readxl)\nwalkingdata &lt;- read_excel(path=\"walkingspeed.xlsx\",\n                          sheet=\"fixed\")\nwalkingdata$department &lt;- factor(walkingdata$department)\nwalkingdata$time &lt;- as.numeric(walkingdata$time)\nwalkingdata$time[walkingdata$time&gt;100] &lt;- NA\nwalkingdata$time[walkingdata$time&lt;1] &lt;- NA\n\nhead(walkingdata)\n\nlibrary(ggplot2)\n\nggplot(walkingdata) +\n  aes(x=group)\n\n\n\n\n# A tibble: 6 × 6\n  patid group    time sex     age department\n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;fct&gt;     \n1     1 treat    1.90 M        53 3         \n2     2 control  3.54 M        61 3         \n3     3 treat    2.93 M        65 1         \n4     4 control  1.82 M        48 2         \n5     5 treat    2.20 M        62 2         \n6     6 control  3.04 M        62 4"
  },
  {
    "objectID": "flipbook.html#section-10",
    "href": "flipbook.html#section-10",
    "title": "Basic ggplot for scientific graphing",
    "section": "",
    "text": "library(readxl)\nwalkingdata &lt;- read_excel(path=\"walkingspeed.xlsx\",\n                          sheet=\"fixed\")\nwalkingdata$department &lt;- factor(walkingdata$department)\nwalkingdata$time &lt;- as.numeric(walkingdata$time)\nwalkingdata$time[walkingdata$time&gt;100] &lt;- NA\nwalkingdata$time[walkingdata$time&lt;1] &lt;- NA\n\nhead(walkingdata)\n\nlibrary(ggplot2)\n\nggplot(walkingdata) +\n  aes(x=group) +\n  aes(y=time)\n\n\n\n\n# A tibble: 6 × 6\n  patid group    time sex     age department\n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;fct&gt;     \n1     1 treat    1.90 M        53 3         \n2     2 control  3.54 M        61 3         \n3     3 treat    2.93 M        65 1         \n4     4 control  1.82 M        48 2         \n5     5 treat    2.20 M        62 2         \n6     6 control  3.04 M        62 4"
  },
  {
    "objectID": "flipbook.html#section-11",
    "href": "flipbook.html#section-11",
    "title": "Basic ggplot for scientific graphing",
    "section": "",
    "text": "library(readxl)\nwalkingdata &lt;- read_excel(path=\"walkingspeed.xlsx\",\n                          sheet=\"fixed\")\nwalkingdata$department &lt;- factor(walkingdata$department)\nwalkingdata$time &lt;- as.numeric(walkingdata$time)\nwalkingdata$time[walkingdata$time&gt;100] &lt;- NA\nwalkingdata$time[walkingdata$time&lt;1] &lt;- NA\n\nhead(walkingdata)\n\nlibrary(ggplot2)\n\nggplot(walkingdata) +\n  aes(x=group) +\n  aes(y=time) +\n\n  geom_boxplot(outlier.shape = NA, fill=NA)\n\n\n\n\n# A tibble: 6 × 6\n  patid group    time sex     age department\n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;fct&gt;     \n1     1 treat    1.90 M        53 3         \n2     2 control  3.54 M        61 3         \n3     3 treat    2.93 M        65 1         \n4     4 control  1.82 M        48 2         \n5     5 treat    2.20 M        62 2         \n6     6 control  3.04 M        62 4"
  },
  {
    "objectID": "flipbook.html#section-12",
    "href": "flipbook.html#section-12",
    "title": "Basic ggplot for scientific graphing",
    "section": "",
    "text": "library(readxl)\nwalkingdata &lt;- read_excel(path=\"walkingspeed.xlsx\",\n                          sheet=\"fixed\")\nwalkingdata$department &lt;- factor(walkingdata$department)\nwalkingdata$time &lt;- as.numeric(walkingdata$time)\nwalkingdata$time[walkingdata$time&gt;100] &lt;- NA\nwalkingdata$time[walkingdata$time&lt;1] &lt;- NA\n\nhead(walkingdata)\n\nlibrary(ggplot2)\n\nggplot(walkingdata) +\n  aes(x=group) +\n  aes(y=time) +\n\n  geom_boxplot(outlier.shape = NA, fill=NA) +\n  scale_y_log10()\n\n\n\n\n# A tibble: 6 × 6\n  patid group    time sex     age department\n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;fct&gt;     \n1     1 treat    1.90 M        53 3         \n2     2 control  3.54 M        61 3         \n3     3 treat    2.93 M        65 1         \n4     4 control  1.82 M        48 2         \n5     5 treat    2.20 M        62 2         \n6     6 control  3.04 M        62 4"
  },
  {
    "objectID": "flipbook.html#section-13",
    "href": "flipbook.html#section-13",
    "title": "Basic ggplot for scientific graphing",
    "section": "",
    "text": "library(readxl)\nwalkingdata &lt;- read_excel(path=\"walkingspeed.xlsx\",\n                          sheet=\"fixed\")\nwalkingdata$department &lt;- factor(walkingdata$department)\nwalkingdata$time &lt;- as.numeric(walkingdata$time)\nwalkingdata$time[walkingdata$time&gt;100] &lt;- NA\nwalkingdata$time[walkingdata$time&lt;1] &lt;- NA\n\nhead(walkingdata)\n\nlibrary(ggplot2)\n\nggplot(walkingdata) +\n  aes(x=group) +\n  aes(y=time) +\n\n  geom_boxplot(outlier.shape = NA, fill=NA) +\n  scale_y_log10() +\n  labs(x=\"Treatment Group\")\n\n\n\n\n# A tibble: 6 × 6\n  patid group    time sex     age department\n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;fct&gt;     \n1     1 treat    1.90 M        53 3         \n2     2 control  3.54 M        61 3         \n3     3 treat    2.93 M        65 1         \n4     4 control  1.82 M        48 2         \n5     5 treat    2.20 M        62 2         \n6     6 control  3.04 M        62 4"
  },
  {
    "objectID": "flipbook.html#section-14",
    "href": "flipbook.html#section-14",
    "title": "Basic ggplot for scientific graphing",
    "section": "",
    "text": "library(readxl)\nwalkingdata &lt;- read_excel(path=\"walkingspeed.xlsx\",\n                          sheet=\"fixed\")\nwalkingdata$department &lt;- factor(walkingdata$department)\nwalkingdata$time &lt;- as.numeric(walkingdata$time)\nwalkingdata$time[walkingdata$time&gt;100] &lt;- NA\nwalkingdata$time[walkingdata$time&lt;1] &lt;- NA\n\nhead(walkingdata)\n\nlibrary(ggplot2)\n\nggplot(walkingdata) +\n  aes(x=group) +\n  aes(y=time) +\n\n  geom_boxplot(outlier.shape = NA, fill=NA) +\n  scale_y_log10() +\n  labs(x=\"Treatment Group\") +\n  labs(y=\"Time (seconds)\")\n\n\n\n\n# A tibble: 6 × 6\n  patid group    time sex     age department\n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;fct&gt;     \n1     1 treat    1.90 M        53 3         \n2     2 control  3.54 M        61 3         \n3     3 treat    2.93 M        65 1         \n4     4 control  1.82 M        48 2         \n5     5 treat    2.20 M        62 2         \n6     6 control  3.04 M        62 4"
  },
  {
    "objectID": "flipbook.html#section-15",
    "href": "flipbook.html#section-15",
    "title": "Basic ggplot for scientific graphing",
    "section": "",
    "text": "library(readxl)\nwalkingdata &lt;- read_excel(path=\"walkingspeed.xlsx\",\n                          sheet=\"fixed\")\nwalkingdata$department &lt;- factor(walkingdata$department)\nwalkingdata$time &lt;- as.numeric(walkingdata$time)\nwalkingdata$time[walkingdata$time&gt;100] &lt;- NA\nwalkingdata$time[walkingdata$time&lt;1] &lt;- NA\n\nhead(walkingdata)\n\nlibrary(ggplot2)\n\nggplot(walkingdata) +\n  aes(x=group) +\n  aes(y=time) +\n\n  geom_boxplot(outlier.shape = NA, fill=NA) +\n  scale_y_log10() +\n  labs(x=\"Treatment Group\") +\n  labs(y=\"Time (seconds)\") +\n  facet_wrap(~sex)\n\n\n\n\n# A tibble: 6 × 6\n  patid group    time sex     age department\n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;fct&gt;     \n1     1 treat    1.90 M        53 3         \n2     2 control  3.54 M        61 3         \n3     3 treat    2.93 M        65 1         \n4     4 control  1.82 M        48 2         \n5     5 treat    2.20 M        62 2         \n6     6 control  3.04 M        62 4"
  },
  {
    "objectID": "flipbook.html#section-16",
    "href": "flipbook.html#section-16",
    "title": "Basic ggplot for scientific graphing",
    "section": "",
    "text": "library(readxl)\nwalkingdata &lt;- read_excel(path=\"walkingspeed.xlsx\",\n                          sheet=\"fixed\")\nwalkingdata$department &lt;- factor(walkingdata$department)\nwalkingdata$time &lt;- as.numeric(walkingdata$time)\nwalkingdata$time[walkingdata$time&gt;100] &lt;- NA\nwalkingdata$time[walkingdata$time&lt;1] &lt;- NA\n\nhead(walkingdata)\n\nlibrary(ggplot2)\n\nggplot(walkingdata) +\n  aes(x=group) +\n  aes(y=time) +\n\n  geom_boxplot(outlier.shape = NA, fill=NA) +\n  scale_y_log10() +\n  labs(x=\"Treatment Group\") +\n  labs(y=\"Time (seconds)\") +\n  facet_wrap(~sex) +\n  theme_bw()\n\n\n\n\n# A tibble: 6 × 6\n  patid group    time sex     age department\n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;fct&gt;     \n1     1 treat    1.90 M        53 3         \n2     2 control  3.54 M        61 3         \n3     3 treat    2.93 M        65 1         \n4     4 control  1.82 M        48 2         \n5     5 treat    2.20 M        62 2         \n6     6 control  3.04 M        62 4"
  },
  {
    "objectID": "flipbook.html#section-17",
    "href": "flipbook.html#section-17",
    "title": "Basic ggplot for scientific graphing",
    "section": "",
    "text": "library(readxl)\nwalkingdata &lt;- read_excel(path=\"walkingspeed.xlsx\",\n                          sheet=\"fixed\")\nwalkingdata$department &lt;- factor(walkingdata$department)\nwalkingdata$time &lt;- as.numeric(walkingdata$time)\nwalkingdata$time[walkingdata$time&gt;100] &lt;- NA\nwalkingdata$time[walkingdata$time&lt;1] &lt;- NA\n\nhead(walkingdata)\n\nlibrary(ggplot2)\n\nggplot(walkingdata) +\n  aes(x=group) +\n  aes(y=time) +\n\n  geom_boxplot(outlier.shape = NA, fill=NA) +\n  scale_y_log10() +\n  labs(x=\"Treatment Group\") +\n  labs(y=\"Time (seconds)\") +\n  facet_wrap(~sex) +\n  theme_bw() +\n  coord_flip()\n\n\n\n\n# A tibble: 6 × 6\n  patid group    time sex     age department\n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;fct&gt;     \n1     1 treat    1.90 M        53 3         \n2     2 control  3.54 M        61 3         \n3     3 treat    2.93 M        65 1         \n4     4 control  1.82 M        48 2         \n5     5 treat    2.20 M        62 2         \n6     6 control  3.04 M        62 4"
  },
  {
    "objectID": "flipbook.html#section-18",
    "href": "flipbook.html#section-18",
    "title": "Basic ggplot for scientific graphing",
    "section": "",
    "text": "library(readxl)\nwalkingdata &lt;- read_excel(path=\"walkingspeed.xlsx\",\n                          sheet=\"fixed\")\nwalkingdata$department &lt;- factor(walkingdata$department)\nwalkingdata$time &lt;- as.numeric(walkingdata$time)\nwalkingdata$time[walkingdata$time&gt;100] &lt;- NA\nwalkingdata$time[walkingdata$time&lt;1] &lt;- NA\n\nhead(walkingdata)\n\nlibrary(ggplot2)\n\nggplot(walkingdata) +\n  aes(x=group) +\n  aes(y=time) +\n\n  geom_boxplot(outlier.shape = NA, fill=NA) +\n  scale_y_log10() +\n  labs(x=\"Treatment Group\") +\n  labs(y=\"Time (seconds)\") +\n  facet_wrap(~sex) +\n  theme_bw() +\n  coord_flip() +\n  ggtitle(\"The relationship between walking\n  speed and treatment group, stratified by sex\")\n\n\n\n\n# A tibble: 6 × 6\n  patid group    time sex     age department\n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;fct&gt;     \n1     1 treat    1.90 M        53 3         \n2     2 control  3.54 M        61 3         \n3     3 treat    2.93 M        65 1         \n4     4 control  1.82 M        48 2         \n5     5 treat    2.20 M        62 2         \n6     6 control  3.04 M        62 4"
  },
  {
    "objectID": "flipbook.html#section-19",
    "href": "flipbook.html#section-19",
    "title": "Basic ggplot for scientific graphing",
    "section": "",
    "text": "library(readxl)\nwalkingdata &lt;- read_excel(path=\"walkingspeed.xlsx\",\n                          sheet=\"fixed\")\nwalkingdata$department &lt;- factor(walkingdata$department)\nwalkingdata$time &lt;- as.numeric(walkingdata$time)\nwalkingdata$time[walkingdata$time&gt;100] &lt;- NA\nwalkingdata$time[walkingdata$time&lt;1] &lt;- NA\n\nhead(walkingdata)\n\nlibrary(ggplot2)\n\nggplot(walkingdata) +\n  aes(x=group) +\n  aes(y=time) +\n\n  geom_boxplot(outlier.shape = NA, fill=NA) +\n  scale_y_log10() +\n  labs(x=\"Treatment Group\") +\n  labs(y=\"Time (seconds)\") +\n  facet_wrap(~sex) +\n  theme_bw() +\n  coord_flip() +\n  ggtitle(\"The relationship between walking\n  speed and treatment group, stratified by sex\")\n\n\n\n\n# A tibble: 6 × 6\n  patid group    time sex     age department\n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;fct&gt;     \n1     1 treat    1.90 M        53 3         \n2     2 control  3.54 M        61 3         \n3     3 treat    2.93 M        65 1         \n4     4 control  1.82 M        48 2         \n5     5 treat    2.20 M        62 2         \n6     6 control  3.04 M        62 4"
  },
  {
    "objectID": "hi.html",
    "href": "hi.html",
    "title": "Untitled",
    "section": "",
    "text": "Hi!"
  },
  {
    "objectID": "independentclusters.html",
    "href": "independentclusters.html",
    "title": "Clustering independent of sampling in observational studies",
    "section": "",
    "text": "We know that random sampling is important to get good inferences from epidemiological studies.\nIf sampling is ‘clustered’ then we need to account for this in our analysis. This is well known.\nHowever we may have a situation where data points are generated in clusters, but we still sample them randomly. Is there a risk of false positive associations in such situations? How should we deal with it?\nHere I use a simple simulation to show that even with random sampling, data that is generated in clusters can still lead us to false positive conclusions."
  },
  {
    "objectID": "independentclusters.html#introduction",
    "href": "independentclusters.html#introduction",
    "title": "Clustering independent of sampling in observational studies",
    "section": "",
    "text": "We know that random sampling is important to get good inferences from epidemiological studies.\nIf sampling is ‘clustered’ then we need to account for this in our analysis. This is well known.\nHowever we may have a situation where data points are generated in clusters, but we still sample them randomly. Is there a risk of false positive associations in such situations? How should we deal with it?\nHere I use a simple simulation to show that even with random sampling, data that is generated in clusters can still lead us to false positive conclusions."
  },
  {
    "objectID": "independentclusters.html#simulation-data",
    "href": "independentclusters.html#simulation-data",
    "title": "Clustering independent of sampling in observational studies",
    "section": "Simulation data",
    "text": "Simulation data\nThe research question here is whether there is a difference between two populations.\nFor the simulation I will create a dataset of 100 points from each population. Each point is sampled independently at random, but arises from one of five clusters in each population. So, to sample each point we first select a cluster at random, then generate a point from that cluster.\nThe cluster averages in turn are selected from a normal distribution with mean zero.\nAn real example question might relate to whether there is a difference in educational attainment between two different cities. We can select children from each city completely at random. But if each city has only five schools then the data points are clustered by school, even if the children are selected completely randomly without any reference to which school they attend.\nSo although children are selected independently of each other, they are still clustered in some sense! Do we still need to run a ‘clustered’ analysis if we are interested in understanding whether ‘city’ has any effect on educational attainment?\nRemember we know that there is no effect of city on average school outcome in our simulation. Differences in outcomes do occur completely randomly at the school level and at the individual child level.\n\nNclusters &lt;- 10\nclustersMeans &lt;- rnorm(Nclusters, 0,1)\n\n## Suppose group A come from clusters 1 to 5\n## Group B come from clusters 6 to 10.\n\nNperGroup &lt;- 100\nGroupAClusters &lt;- sample(1:5,NperGroup, replace=TRUE)\nGroupBClusters &lt;- sample(6:10,NperGroup, replace=TRUE)\n\ndat &lt;- data.frame(Group=rep(c(\"A\",\"B\"),each=NperGroup), cluster=c(GroupAClusters, GroupBClusters))\ndat$y &lt;- rnorm(NperGroup*2 , clustersMeans[dat$cluster], 1)\n\nhead(dat)\n\n  Group cluster           y\n1     A       1  2.17314644\n2     A       4  0.23199408\n3     A       4 -0.14176686\n4     A       2  1.05632863\n5     A       4  0.15161343\n6     A       3  0.08051086\n\n\nNow we can plot the data:\n\nlibrary(ggplot2)\n\ndat |&gt; ggplot(aes(x=Group, y=y, shape=factor(cluster))) + \n  scale_shape_manual(values=1:10) + \n  geom_point(position = position_dodge2(width=0.2)) + theme_bw()\n\n\n\n\nThe clustering is evident in the plot. How does this affect the p-values for a linear model? Do we need to use a LMM?\n\n## A naive linear model would suggest a difference between groups\nlm(y ~ Group , data=dat) |&gt; broom::tidy()\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic     p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n1 (Intercept)    0.286     0.111      2.56 0.0111     \n2 GroupB        -0.821     0.158     -5.21 0.000000480\n\n## While mixed model taking the clustering into account does not\nlmer(y ~ Group + (1|cluster), data=dat) |&gt; broom.mixed::tidy() |&gt; subset(effect==\"fixed\")\n\n# A tibble: 2 × 8\n  effect group term        estimate std.error statistic    df p.value\n  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 fixed  &lt;NA&gt;  (Intercept)    0.313     0.291      1.07  8.08  0.313 \n2 fixed  &lt;NA&gt;  GroupB        -0.913     0.412     -2.22  8.08  0.0571\n\n\nSo if we ignore the clusters we get a false positive result (p&lt;0.001), but if we incorporate them into our analysis we do not."
  },
  {
    "objectID": "independentclusters.html#type-1-error-rate",
    "href": "independentclusters.html#type-1-error-rate",
    "title": "Clustering independent of sampling in observational studies",
    "section": "Type 1 error rate",
    "text": "Type 1 error rate\nTo quantify the problem we can look at how the false positive rate changes with the extent of the clustering.\nWe’ll simulate datasets and analysis 1000 times for each value of the cluster standard deviation, from 1.0 (the same as the between individual standard deviation) to zero. Then we’ll look at the proportion of statistically significant results (p&lt;0.05), and compare this to the nominal 5% rate.\nIn each simulation we generate new cluster means, and then a new dataset of points. We then apply the simple linear model and a mixed effects model, and extract the p-values for the hypothesis test that the effect of ‘population’ is zero.\n\noneRep &lt;- function(clusterSD){\n  clustersMeans &lt;- rnorm(Nclusters, 0,clusterSD)\n  dat$y &lt;- rnorm(NperGroup*2 , clustersMeans[dat$cluster], 1)\n  plmer &lt;- (lmer(y ~ Group + (1|cluster), data=dat) |&gt; summary() |&gt; coef())[2,5]\n  plm &lt;- (lm(y ~ Group , data=dat) |&gt; summary() |&gt; coef())[2,4]\n  c(plmer,plm)\n}\n\npvals &lt;- lapply(c(1.0,0.8,0.6,0.4,0.2,0.0) , \\(s) replicate(1000,oneRep(s)))\n\nsignificant &lt;- sapply(pvals, apply, 1, \\(p) mean(p&lt;0.05)) |&gt; t() |&gt; as.data.frame() |&gt; setNames(c(\"Mixed model\", \"Simple Linear model\"))\nsignificant$clusterVariance &lt;- c(1.0,0.8,0.6,0.4,0.2,0.0)\n\nsignificant &lt;- data.table::melt(significant, id.vars=\"clusterVariance\", variable.name=\"Method\", value.name=\"rate\")\n\nggplot(significant) + aes(x=clusterVariance, y=rate, col=Method) + geom_point() + geom_line() + \n  geom_hline(yintercept=0.05, lty=\"dashed\") + \n  labs(x=\"Between cluster standard deviation\", y=\"Type 1 error rate\")"
  },
  {
    "objectID": "independentclusters.html#conclusion-and-discussion",
    "href": "independentclusters.html#conclusion-and-discussion",
    "title": "Clustering independent of sampling in observational studies",
    "section": "Conclusion and Discussion",
    "text": "Conclusion and Discussion\nThe type 1 error rate increases markedly with the among of variance between ‘clusters’ when a simple linear model is used. A mixed model broadly corrects this, and may over-compensate when the between-cluster variance is very low.\nSo for our school analogy, if schools are very variable, then if we don’t model the clustering it may look like there are inherent differences between cities instead of there simply being random differences between the schools that are not attributable to the city they are in.\nWhether this is the correct or incorrect answer depends on exactly what the question is that we are trying to answer, that is whether we are trying to (1) identify the city that just happens (by chance) to have the best schools, or (2) whether we are asking about whether the city itself promotes good schools or good outcomes.\nIn most situations we are asking the latter question in which case we need to include the grouping in our analysis to get a meaningful result.\nTo generate our simulated datasets we included no effect of the grouping factor on the cluster means or the individual means, and we sampled each unit independently from the population. Yet a simple linear model (equivalent of t-test or ANOVA) returned a strongly significant effect. This was corrected by considering the shared variance within clusters in our model.\nThis should be another reminder that to avoid looking silly we need to understand how our datasets come to be, and what shared variance there is between our observations, even if we know that our samples are generated from our populations using simple random sampling."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R and RStudio for Statistics",
    "section": "",
    "text": "This site hosts my course notes, presentations and data files accompanying my courses on R and RStudio.\nThere are also some general notes on statistics that I have created for myself (for exploring different ideas) or to help others.\n\nNBI/JIC MSc Introduction to R\n\nDay 1\nDay 2\nDay 2 (MSc version)\nDay 3\n\nStatistics notes\n\nDon’t dichotomise your data\nSimple alpha and beta diversity simulation\nSelection bias (Berkson bias) in observational studies\nSampling from clustered data in observational studies\nRun bigger experiments instead of internal replications of smaller experiments\n\nNotes on using R\n\nTidyverse, data.table and others for making descriptive tables\nUsing packages, functions and pipes\nUsing ggplot2\n\n\nOlder stuff\n\nJIC MSc Workshop (2021/2022)\n\nTutorial"
  },
  {
    "objectID": "praise.html",
    "href": "praise.html",
    "title": "Packages and Pipes",
    "section": "",
    "text": "R is mainly for statistical computing but there are add-on packages to do many other things. You are likely to need to use add-on packages for reading Excel files, data manipulation, running specific analyses, creating nice reports etc.\nIn this tutorial we will get used to using R packages, objects, functions, pipes and how to use the R help system by making ascii animals say nice things to us."
  },
  {
    "objectID": "praise.html#ok-thats-enough-fun.",
    "href": "praise.html#ok-thats-enough-fun.",
    "title": "Packages and Pipes",
    "section": "5.1 OK that’s enough fun.",
    "text": "5.1 OK that’s enough fun.\nOK now back to the real work."
  },
  {
    "objectID": "repeats.html",
    "href": "repeats.html",
    "title": "Running bigger experiments is better than internal replication of smaller experiments",
    "section": "",
    "text": "TLDR: Internal replication of experiments (repeatedly running the same experiment within a lab) is unnecessary and wasteful, if your experiments are well designed to start with.\nExternal replication (later replication of ideas or experiments by different people in different contexts) is not discussed here."
  },
  {
    "objectID": "repeats.html#introduction",
    "href": "repeats.html#introduction",
    "title": "Running bigger experiments is better than internal replication of smaller experiments",
    "section": "Introduction",
    "text": "Introduction\nAt the end of a long conversation on the importance of experimental design and why nobody likes talking to statisticians, a colleague finally dismissed the possibility of erroneous findings with “..but of course, we always repeat all our experiments three times anyway.” Up until now, in the interests of collegiality and to avoid being considered a troublemaker, I’ve let these sorts of provocations slide. But this was the third time in as many weeks that experiments in triplicate had been presented to me as obviously necessary despite having no apparent statistical basis.\nOnline searches revealed that ‘why do biologists replicate everything three times?’ is a question occasionally asked by newcomers to the field but never satisfactorily answered, and revealed a lot of confusion about the role of technical replicates, biological replicates, internal vs external replicates of experiments, when each is necessary and what each is for. Peer-reviewed literature, grey literature and textbooks seem also to be fairly quiet on the topic of this ‘internal’ replication, despite its (apparent?) widespread use.\nIn honesty it’s been a while since I thought about this, but I was recently motivated to revisit this topic by the MRC guidance for the design of animal experiments in funding applications, which states:\n\n[we require] an indication of the number of independent replications of each experiment to be performed with the objective of minimising the likelihood of spurious non replicable results. If there are no plans for studies to be independently replicated within the current proposal then this will need to be justified.\n\nIt’s not completely clear what the MRC mean by this, but if you want to argue against running repeats of experiments (and perform single better larger experiments instead) then this essay might help you with your justification. Below I explore some of the statistical implications of this strategy for error control, compared to a (more conventional?) approach of using a single larger (possibly blocked) experiment, and discuss what this reveals about how statisticians and biologists think about what scientific experiments can ever actually tell us.\nSpecifically, I discuss a strategy whereby a researcher repeats their experiment three times, and then considers a finding to have been demonstrated (positive or negative) if two of the three agree. I’ll call this the ‘2 of 3’ strategy."
  },
  {
    "objectID": "repeats.html#face-validity",
    "href": "repeats.html#face-validity",
    "title": "Running bigger experiments is better than internal replication of smaller experiments",
    "section": "Face validity",
    "text": "Face validity\nOn the face of it, replicating an experiment three times does seem like reasonable mitigation against the false positive or false negative arising from a single trial.\nThat is, if something does work on at least two out of three occasions, wouldn’t you be reasonably sure that it was going to work again or at least was reflecting an underlying biological truth? Whereas if your experiment failed at least two times out of three wouldn’t you think it likely that the anomalous positive was the result of some fluke or technical error?\nWell yes, and no.\nFalse positives or negatives due to biases or natural variation are inevitable, and are exactly what good experimental design and analysis are there to control. And if experiment 1 still does go wrong in an unknowable and uncontrollable way, surely there’s a good chance that experiments 2 and 3 will behave similarly? And if you are studying an effect that genuinely varies across subpopulations, or with time, place or the alignment of the stars, then you need to design and analyse your experiment accordingly.\nBut is there any actual harm in taking this approach, and what threshold for discovery are you in fact demanding of your experiments if you do this? This clearly needs some exploration; to understand what the statistical properties of this process of replication are, and how can we get the desired outcome (low error rates and good generalisability) in as efficient a way as possible."
  },
  {
    "objectID": "repeats.html#the-implications-of-repeating-three-times-on-error-rates",
    "href": "repeats.html#the-implications-of-repeating-three-times-on-error-rates",
    "title": "Running bigger experiments is better than internal replication of smaller experiments",
    "section": "The implications of repeating three times on error rates",
    "text": "The implications of repeating three times on error rates\nSo what are the implications of using your valuable time, energy and mice to repeat every experiment on three separate occasions, and then democratically deciding among the replicates which answer is the truth? Let’s work this out in a simple hypothetical case.\nSuppose you consult your statistician (humour me) and plan a well designed experiment to test a null hypothesis (H0) against an alternative (H1) such that the experiment has a power of 80% at a size of 0.05 (that is, you determine statistical significance at p&lt;0.05).\nThen you run this experiment three times, and only accept the result as true (reject H0) if at least two of the three results agree. Let’s ignore for now the possibility that findings could be statistically significant but in opposite directions.\nWhat are the error rates of this combined experimental procedure (the 2 of 3 strategy) as a whole?\n\nImplications for power (or type 2 error rate)\nFirst, let’s work out the power. This is probability of detecting an effect if that effect was in fact there (a true positive). Each individual experiment has, independently, a power of 80%. You need at least two of the three to show statistical significance.\nThe chance of this happening is the simple binomial probability:\n\\(0.8^3 + 3\\times 0.8^2\\times 0.2 = 0.896\\)\nSo if H1 is true you have a 89.6% chance of getting a positive result using this procedure, corresponding to a Type 2 error rate of 10.4%. This is an improvement on the 20% type 2 error rate for the single trial with 80% power.\n\n\nImplications for size\nWhat about false positive rate? If there is no effect (H0 is true) and your size is 0.05, that is you require p&lt;0.05 in each individual trial, then the chance of a false positive for your two in three procedure is again easy to find:\n\\(0.05^3 + 3×0.05^2×0.095 = 0.0075\\)\nSo a less than 1% chance of a false positive if H0 is true!\nSo this looks great! With three repeats (using the 2 from 3 strategy) you have reduced the risk of a false positive (if no real effect) from 5% to 0.75%, and increased power from 80% to as good as 90%!\nBut this has come at a cost of needing three times as much resource.\n\n\nEquivalent single experiment\nWas it worth it? How big would a single well-designed experiment have to be to achieve the same power and size? If your initial goal had been to design an experiment with power of 89.6% and size of 0.0075, what sample size would have been needed?\nWe can find this using a power and sample size calculator. (R code available)\nIf we work out the effect size needed such that any given N (our original single trial sample size) yields a power of 80% and size of 0.05, and then require that for the same effect size we want a power of 89.6% and a size of 0.0075, then the ratio of the original N to the revised N will reflect how much extra sample size we need.\nIt turns out that this same improvement in error rates is achieved with almost exactly 2N samples.\nSo by running one well designed experiment with twice the sample size instead of using three repeats, you will achieve the same error control with two thirds of the time and material you would otherwise have needed.\n\n\nOptional stopping\n“But wait!” you retort. “I would obviously only conduct experiment 3 if experiments 1 and 2 were in conflict. So I will not often use all three repeats.”\nThis is a good point. We can work out the probability of you actually needing all three experiments, hence what your expected average gain would be by using a single larger experiment instead.\nBut we do need to introduce another parameter, the probability that your supposed effect is real (that is, H1 is true). For any such probability, the chance that your first two experiments agree is shown below:\n\n\n\nThe probability of two experiments with 80% power and 5% size ‘agreeing’, depending on the probability that the underlying effect is true\n\n\nSo in all cases there’s actually a good chance (between 70% and 90%) that you’ll stop before needing the third trial. So the average cost of this 2 of 3 procedure is between 2.1 and 2.3 times N, the original sample size of each trial (so long as you stop after two trials that agree), compared with only 2.0 times N for running one large experiment. (Also, if we’re going to use optional stopping we can probably design a more efficient experiment in the first place).\nSo, all things considered, this isn’t an enormous improvement. In this case, where the original study was well designed, and if you stop after two trials with the same result then you’ll save roughly 10% of your resources by using a single larger experiment to get your error control rather than a strategy of 2 in 3 small experiments.\nSo in this case at least, using the 2 of 3 trials is a isn’t a terribly inefficient way to improve your Type 1 and Type 2 error rates. But the point does still stand that you get the same error rate control with 2N samples instead of needing the possibility of the third replicate, so long as you analyse them as one big experiment and not two smaller ones that may or may not agree.\n\n\nUnderpowered studies\nAll of the above supposed that the three individual independent experiments were each well designed to begin with. Suppose however that your initial experiment was underpowered, such that you only had a 50% chance of detecting a real effect at p&lt;0.05.\nIn this underpowered case your 2 of 3 strategy yields a power of 0.5, so there is no increase in power at all. Your Type 1 error is still 0.0075 though, so you have still improved type 1 error control by running three reps. The equivalent single stage experiment would need to have a sample size of 1.9 times the size of a single trial to achieve this error control criteria, and the chance of stopping after 2 is between 0.9 and 0.5 (say 0.7) depending on the chance that your hypothesis is actually true.\nSo your expected cost for the 2 of 3 strategy is 2.3N, while your known cost for a single larger study with the same error control is 1.9N. So you would save about a 0.4N or roughly a fifth of your expected resource by using a single experiment rather than having a strategy of needing 2 in 3 internal reps to be significant.\nIf your experiment is even more poorly powered, say at 30%, then the power of the 2/3 strategy is 0.3^3 + 30.3^20.7 = 0.216. So you lose power compared to a single trial. To get the same effect with a single study you’d need 1.75*N samples. Your probability of stopping early is around 0.75 (between 0.6 and 0.9), even though in a lot of cases you’d stop erroneously if the alternative hypothesis was true. So here the saving is 2.25 - 1.75 = 0.5N; again that’s just over a fifth of your expected size under the 2/3 strategy.\n\n\nReporting\nSo far I have only discussed error rates and statistical significance. The question of how you might report experimental results when you’ve used internal replication is complex.\nClearly, only showing one trial (say the first one, or a ‘representative’ trial) is an inefficient use of data, hides data, and is unacceptable. Selecting a ‘significant’ trial to support a significant finding is biased, while risking selecting a ‘non-significant’ trial to reflect an overall significant result is non-sensical. It is clear that reporting all of the data from all of the trials you have conducted is the only correct way to proceed, along with a clear description of the process by which you decided to stop conducting more studies, but this would be messy and far more difficult to interpret than simply conducting and reporting a single experiment in the first place. In short, unbiased and efficient reporting is very difficult if you are using internal replication at the level of the experiment."
  },
  {
    "objectID": "repeats.html#so-why-do-we-intuitively-have-more-trust-in-a-replicated-experiment",
    "href": "repeats.html#so-why-do-we-intuitively-have-more-trust-in-a-replicated-experiment",
    "title": "Running bigger experiments is better than internal replication of smaller experiments",
    "section": "So why do we intuitively have more trust in a replicated experiment?",
    "text": "So why do we intuitively have more trust in a replicated experiment?\nI have shown that running one big experiment is a better use of resources than two or three small ones, if the goal is to control false positive and false negative risk, and it seems obvious that a single large experiment is much easier to report than lots of small ones.\nBut casting aside the maths, at some human level I think that even would I intuitively have more faith in an idea if it is demonstrated more than once in small experiments, compared to being shown exactly once in a large experiment, even if that large experiment is statistically just as good as a set of small ones.\nSo what is going on? Can we model this (erroneous) thinking more formally to see where the problem lies?\nMy theory is as follows:\nScientists (perhaps people) don’t think about type 1 and type 2 error rates when designing, analysing or interpreting experiments. Nor do they typically see experiments as estimating some unknown population-level quantity. Instead, experiments are viewed as tests of whether an effect exists, reflected almost completely by the statistical significance of the outcome (that is whether the experiment worked or did not).\nIn a way this is natural, and our (wrong) notion of replicability reflects and reinforces this. The idea that if you replicate an experiment you should get the same result again and again is an intuitively attractive and often stated one, but it’s wrong. P-values are very unreliable. Two identical experiments can be perfectly consistent with each other even if they return very different p-values. In fact their results should always be different, because of the role of chance. (Replication results with p-values that are too similar are viewed with extreme suspicion by many).\nReplicability does not mean that the same experiment repeated should generate the same qualitative result. It does mean that the estimates arising from them should be close enough together such that their difference is attributable to natural variation in the outcome measures.\nFor example, if an experiment has 50% power under a ‘true’ effect, then statistical significance under H1 is a coin toss. The ‘results’ of successive experiments will be random and completely independent of each other, yet this is no reason to consider them inconsistent.\nBut under this (bad) interpretation, it’s easy to see why seeing successive positive results from repeated experiments is more appealing than seeing one positive from a single large experiment. It’s also easy to see how this reinforces the idea that experiments are likely to randomly ‘fail’ for mysterious methodological reasons, as under this way of thinking there is no other way to account for experimental inconsistency.\nSo, suppose we believe that our experiments should ‘work’ if the idea underlying them is correct, they should ‘not work’ if it is not, and that any deviation from this is caused by methodological error (which occurs with unknown probability independently of the size of the study). Under this model getting one success from one trial tells us almost nothing. It could be an error; it could be a true discovery and we have no way of saying which. Yet if we see two out of three trials work, then we may start to believe the more parsimonious explanation that one out of the three is a false negative rather than two out of three being false positives, which strengthens our belief in the finding.\nThe central fault(s) in this reasoning is the failure to appreciate that:\n\nAll experiments have both type 1 and type 2 error rates,\nthese errors do not occur because the experiments are faulty but occur due to chance,\nthese will naturally lead to apparently inconsistent findings, particularly if studies are underpowered, and\nlarge studies have smaller error rates, and are more reliable, such that we should update our beliefs by a greater amount based on larger studies compared to smaller ones.\n\nI agree that errors due to methodological failures can and do occur. However, splitting resources across two or three smaller trials, each of which is analysed separately, (ie internal replication) does not remove any of the randomness or methodological issues present in the alternative larger study, but does inflate their ability to derail our interpretations.\nConversely there is nothing to suggest that that a bias built into in a single study wouldn’t also be present in a replicate. In fact you’d expect that it would be. Good experimental design, good monitoring, analysis using models that can account for this variation (or random human error) and an appreciation of the ‘estimation’ paradigm for analysis is the appropriate response to this challenge, not the ‘brute force’ and frankly illusory safety net of internal replication.\nFor example, if we believe in a day-to-day variation in results that leads us to want to replicate across different days, then we can design a single blocked experiment and conduct it over multiple days, such that any ‘day’ effect is balanced over treatment conditions and a day-by-treatment effect might be estimated.\n\nSide notes and caveats\nThis is not to downplay the importance of biological replication. Biological replication is essential, and we should tend to emphasize biological replicates over technical replicates where possible. Where a source of variation exist, experiments should include replication across that source. But we should still always analyse our replicates together as part of a single experiment.\nIf we do want to retain the possibility of optional stopping, whereby we allow the possibility of getting more samples if uncertainty remains after an initial analysis, then we can, and I advocate this where appropriate, but it must be explicit in the original design, accounted for in analysis and acknowledged in the interpretation.\nExternal independent replication of published findings is also important, adds generalisability, and, given the state of the published literature, is more crucial than ever. But the aims of external replication are very different to those of internal replication.\nThis does not apply to internal replication of computational pipelines, which I think is a good idea (advocated here https://www.bitss.org/internal-replication-another-tool-for-the-reproducibility-toolkit/)\n\n\nDiscussion\nDrilling into the statistical properties of a strategy that relies on internal replication of experiments and the possible reasons for their intuitive appeal leads to clear practical suggestions and highlights some potential misunderstandings regarding the meaning of replicability and even the role of experiments and what should be inferred from them.\n\n\nSummary:\nA strategy of reporting an effect when two out of three independent trials rejects H0 at p&lt;0.05 has an overall type 1 error of 0.0075 (ie is equiv. to a single experiment reporting at p&lt;0.0075).\nWhether the power of this strategy is greater or less than the power of each individual experiment depends on whether each individual study is adequately powered in the first place. If each study is underpowered then the chance of true positive with this strategy is very low, if each individual trial is well powered then it is high.\nAn alternative strategy of running a single larger trial with the same error rates has a smaller expected sample size required in all situations tested, typically between 10 and 25% less, and is more predictable with respect to the resources needed. Using the ‘2 in 3’ strategy risks wasting more than 50% additional time and resources in the case that the third trial is needed to arbitrate between apparent inconsistencies from the first two.\nGood reporting of results from a single larger study is much easier than reporting based on a strategy of internal experimental repeats, and this uses available data much more efficiently.\nStudies are not inconsistent just because one reports a statistically significant difference while the other does not. Consistency of study findings should be judged based on whether the difference between their estimates is commensurate with the precision of each estimate. It is simply impossible to judge this with p-values alone.\nMajor sources of misunderstanding are the over-reliance on ‘statistical significance’ as the summary statistic for experimental results, which does not permit us to give more weight to larger trials compared to smaller ones, and the failure to consider type 2 errors as a source of apparent inconsistency between trials.\n\n\nRecommendations\nInternal replication of studies with identical conditions should be discouraged, where these would have been used, larger studies with more ‘biological’ replicates and stricter thresholds for error control can instead be safely recommended. These larger studies should be well designed, a good starting point for design would be using the proposed smaller studies as blocks within the larger design.\nWhere replicates have been made, we must not report findings from ‘a representative’ experiment, but should instead pool data using an appropriate method for pooling such as a mixed effects model or meta-analysis.\nStudies should be reported using estimates of differences along with the standard errors of differences or confidence intervals for differences, rather than relying on p-values.\n\n\nExisting literature (todo - fix this and add more)\nThere isn’t much literature on the value or otherwise of internal replications of experiments. I have certainly never seen a publication that formally explores and advocates this.\nThis author has roughly the same view I do. https://www.cell.com/trends/plant-science/fulltext/S1360-1385(99)01439-9.\nI couldn’t find anything on internal replication in the NC3RS website, except that the ARRIVE guidelines for reporting (rightly) insist that it is described when it was done.\nFor good introductory reading on types of replication and how to design and analyse studies with replicates appropriately, I would recommend Lazic (2016) Experimental Design for Laboratory Biologists.\nRecently with the ‘replication crisis’ there has been an instinctive reaction to do more internal replication in psychology. A blog post and an article show theoretically and empirically that this is not helpful.\nhttps://brainsidea.wordpress.com/2015/09/05/are-internal-replications-the-solution-to-the-replication-crisis-in-psychology-no/\nhttps://link.springer.com/article/10.3758/s13423-016-1030-9\nThere is a lot written more generally about the importance of replication in science.\nhttps://www.aje.com/arc/why-is-replication-in-research-important/"
  },
  {
    "objectID": "workshopscript.html",
    "href": "workshopscript.html",
    "title": "JIC MSc Workshop: Analysis Walkthrough",
    "section": "",
    "text": "Introduction\nThis page supports a short workshop in R and RStudio for Statistics. It is not intended as a comprehensive tutorial but as a vehicle for demonstrating and discussing some aspects of a typical analysis using R, with signposting in the lecture notes for further self-directed learning.\nA simple dataset is introduced along with some research questions and I demonstrate a typical process of loading, visualising, cleaning, analysing and reporting the analysis. The workshop will very briefly introduce:\n\nthe RStudio interface\nsources of help\nusing projects and scripts\nbasics of the R language\nloading data from excel\ntidy data\nthe tidyverse and data.table systems for data wrangling\nmerging and appending datasets\nrunning a R function with named arguments\nthe formula interface\nhow to estimate a linear models\nggplot\n\nSupporting material (presentation slides, dataset) is linked.\nA more detailed R tutorial is also available on this site.\n\n\nBackground to the dataset\nWe have an Excel spreadsheet with data corresponding to a rehabilitation intervention for stroke patients.\nHospital patients were recruited from five hospital departments and were randomised to either standard care or an experimental treatment. The time they took to complete a walking speed task was recorded as the outcome. A lower time corresponds to a better outcome.\nThe dataset is here walkingspeed.xlsx: A R script including only the R command needed for the analysis is here: workshopscript.R:\nWe will answer the following questions:\n\nWhat is the mean and standard deviation of walking speed in each treatment group?\nDoes the treatment improve walking speed?\nIs the treatment effect different between men and women?\n\nOur workflow is typical of most staistical analyses:\n\nLoad data\nWrangle\nDescribe\nVisualise\nClean and recode\nTest and model\nReport\n\n\n\nSet up\nWe will need to install the libraries below if we don’t already have them. We should also start a new project in the project directory, and download the data and the code if necessary.\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(data.table)\n\nWarning: package 'data.table' was built under R version 4.2.2\n\n\n\nAttaching package: 'data.table'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    between, first, last\n\nlibrary(readxl)\n\nWarning: package 'readxl' was built under R version 4.2.2\n\n\n\n\nLoad data\nWe should inspect the data in Excel. Note there are three sheets that we need to combine to do our analysis.\nReview the “tidy data” powerpoint presentation here: day2_tidydata.pptx.\n\ntreated &lt;- read_excel(path=\"walkingspeed.xlsx\", \n                      sheet = \"treated\",\n                      range = \"A1:B68\")\n\nNotes:\n\nThe library readxl for reading Excel sheets. There are alternatives but I find this works well.\nMultiline function call\nNamed arguments\nAssigning the outcome to the variable\nHelp file, how did we know how this function worked.\n\nWe need to load all three sheets as separate data frames.\n\ncontrol &lt;- read_excel(path=\"walkingspeed.xlsx\", \n                      sheet = \"control\",\n                      range = \"A1:B70\")\n\nmetadata &lt;- read_excel(path=\"walkingspeed.xlsx\", \n                      sheet = \"meta\",\n                      range = \"A1:D139\")\n\n\n\nExplore data\nR includes several functions to inspect data\n\nclass(treated)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nstr(treated)\n\ntibble [67 × 2] (S3: tbl_df/tbl/data.frame)\n $ patid: num [1:67] 1 3 5 7 9 11 13 15 17 19 ...\n $ time : chr [1:67] \"1.8975120000000001\" \"2.927432\" \"2.2042579999999998\" \"2.1441910000000002\" ...\n\nsummary(treated)\n\n     patid         time          \n Min.   :  1   Length:67         \n 1st Qu.: 34   Class :character  \n Median : 67   Mode  :character  \n Mean   : 67                     \n 3rd Qu.:100                     \n Max.   :133                     \n\nhead(treated)\n\n# A tibble: 6 × 2\n  patid time              \n  &lt;dbl&gt; &lt;chr&gt;             \n1     1 1.8975120000000001\n2     3 2.927432          \n3     5 2.2042579999999998\n4     7 2.1441910000000002\n5     9 1.7203250000000001\n6    11 2.1476410000000001\n\n# View(treated)\nstr(control)\n\ntibble [69 × 2] (S3: tbl_df/tbl/data.frame)\n $ patid   : num [1:69] 2 4 6 8 10 12 14 16 18 20 ...\n $ walktime: num [1:69] 3.54 1.82 3.04 2.47 2.48 ...\n\n\nNotes:\n\nData can be numeric, character strings, (factors or logical)\nDo we know what each of these types is for?\n\n\n\nAccess elements from the dataframe\n\ncontrol$walktime\n\n [1]   3.537158   1.819787   3.038065   2.469580   2.483921   2.440482\n [7]   2.779616   3.739146   1.956132   5.415308   3.067604 185.362000\n[13]   2.690378   0.015400   2.716427   1.952741   2.707647   5.056214\n[19]   3.319593   1.493927   2.654815   2.856972   2.401613   1.714169\n[25]   3.183433   2.897221  10.590513   2.572139   2.380559   3.528461\n[31]  12.168967   2.274398   2.631071   2.524958   2.191847   3.943916\n[37]   3.390101   5.146895   2.426002   3.340182   2.392610   2.375177\n[43]   2.210679   3.344224   2.233431   2.749903   3.361010   2.803598\n[49]   4.499523   3.642821   2.225054   2.318357   2.241562   2.498969\n[55]   2.378422   2.370767   2.169139   2.373494   2.959015   3.881843\n[61]   2.296210   3.075860   5.033359   2.870730   3.980520   2.290122\n[67]   1.843314   2.083927   2.778637\n\ncontrol$walktime[1]\n\n[1] 3.537158\n\ncontrol$walktime[1:10]\n\n [1] 3.537158 1.819787 3.038065 2.469580 2.483921 2.440482 2.779616 3.739146\n [9] 1.956132 5.415308\n\nmean(control$walktime)\n\n[1] 5.712487\n\nmean(control$walktime[1:5])\n\n[1] 2.669702\n\nlog(control$walktime)\n\n [1]  1.2633236  0.5987195  1.1112208  0.9040481  0.9098384  0.8921956\n [7]  1.0223128  1.3188572  0.6709691  1.6892298  1.1208968  5.2223107\n[13]  0.9896817 -4.1733878  0.9993174  0.6692340  0.9960800  1.6206180\n[19]  1.1998422  0.4014082  0.9763750  1.0497623  0.8761406  0.5389284\n[25]  1.1579602  1.0637520  2.3599586  0.9447378  0.8673353  1.2608618\n[31]  2.4988890  0.8217154  0.9673910  0.9262244  0.7847446  1.3721741\n[37]  1.2208597  1.6383936  0.8862446  1.2060253  0.8723848  0.8650720\n[43]  0.7932997  1.2072347  0.8035390  1.0115656  1.2122415  1.0309036\n[49]  1.5039714  1.2927584  0.7997812  0.8408587  0.8071729  0.9158782\n[55]  0.8664372  0.8632135  0.7743303  0.8643631  1.0848564  1.3563100\n[61]  0.8312599  1.1235845  1.6160876  1.0545664  1.3814125  0.8286051\n[67]  0.6115650  0.7342541  1.0219605\n\nlog(control$walktime[1:5])\n\n[1] 1.2633236 0.5987195 1.1112208 0.9040481 0.9098384\n\n\n\n\nWrangle\nFor analysis we will need all the data into one data frame. We need to append (row bind) the treatment and control results, then merge (join) the meta data.\n\n# Remind ourselves of the structure of the dataset\nstr(treated)\n\ntibble [67 × 2] (S3: tbl_df/tbl/data.frame)\n $ patid: num [1:67] 1 3 5 7 9 11 13 15 17 19 ...\n $ time : chr [1:67] \"1.8975120000000001\" \"2.927432\" \"2.2042579999999998\" \"2.1441910000000002\" ...\n\nstr(control)\n\ntibble [69 × 2] (S3: tbl_df/tbl/data.frame)\n $ patid   : num [1:69] 2 4 6 8 10 12 14 16 18 20 ...\n $ walktime: num [1:69] 3.54 1.82 3.04 2.47 2.48 ...\n\n\nWe need to make sure the vectors we are merging have the same type and name!\nThere are a lot of ways to do the same thing. Here I am illustrating the ‘base’ R way, the ‘tidyverse’ way and the ‘data.table’ way to convert a new numeric variable from a character variable.\n\n# Base R\ntreated$walktime &lt;- as.numeric(treated$time)\n\nWarning: NAs introduced by coercion\n\n# data.table\nsetDT(treated)\ntreated[ , walktime := as.numeric(time)  ]\n\nWarning in eval(jsub, SDenv, parent.frame()): NAs introduced by coercion\n\n# tidyverse\ntreated &lt;- treated %&gt;% mutate(walktime = as.numeric(time))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `walktime = as.numeric(time)`.\nCaused by warning:\n! NAs introduced by coercion\n\n\nNow we can append the rows and merge them with the metadata. Again there is a tidyverse function for this, and a data.table function for this.\n\n# data.table\ncombined &lt;- rbind(treated, control, fill=TRUE)\ncombined &lt;- rbind(treated=treated, \n                  control=control, \n                  fill=TRUE, idcol=\"group\")\n# tidyverse\ncombined &lt;- bind_rows(treated, control)\ncombined &lt;- bind_rows(treated = treated, \n                      control = control, \n                      .id = \"group\")\n\nstr(metadata)\n\ntibble [138 × 4] (S3: tbl_df/tbl/data.frame)\n $ patient   : num [1:138] 1 2 3 4 5 6 7 8 9 10 ...\n $ sex       : chr [1:138] \"M\" \"M\" \"M\" \"M\" ...\n $ age       : num [1:138] 53 61 65 48 62 62 57 57 57 55 ...\n $ department: num [1:138] 3 3 1 2 2 4 2 4 3 2 ...\n\nstr(combined)\n\nClasses 'data.table' and 'data.frame':  136 obs. of  4 variables:\n $ group   : chr  \"treated\" \"treated\" \"treated\" \"treated\" ...\n $ patid   : num  1 3 5 7 9 11 13 15 17 19 ...\n $ time    : chr  \"1.8975120000000001\" \"2.927432\" \"2.2042579999999998\" \"2.1441910000000002\" ...\n $ walktime: num  1.9 2.93 2.2 2.14 1.72 ...\n - attr(*, \".internal.selfref\")=&lt;externalptr&gt; \n\nwalkingdata &lt;- merge(combined, metadata, \n                by.x = \"patid\", by.y = \"patient\")\n\nhead(walkingdata)\n\n   patid   group               time walktime sex age department\n1:     1 treated 1.8975120000000001 1.897512   M  53          3\n2:     2 control               &lt;NA&gt; 3.537158   M  61          3\n3:     3 treated           2.927432 2.927432   M  65          1\n4:     4 control               &lt;NA&gt; 1.819787   M  48          2\n5:     5 treated 2.2042579999999998 2.204258   M  62          2\n6:     6 control               &lt;NA&gt; 3.038065   M  62          4\n\nstr(walkingdata)\n\nClasses 'data.table' and 'data.frame':  136 obs. of  7 variables:\n $ patid     : num  1 2 3 4 5 6 7 8 9 10 ...\n $ group     : chr  \"treated\" \"control\" \"treated\" \"control\" ...\n $ time      : chr  \"1.8975120000000001\" NA \"2.927432\" NA ...\n $ walktime  : num  1.9 3.54 2.93 1.82 2.2 ...\n $ sex       : chr  \"M\" \"M\" \"M\" \"M\" ...\n $ age       : num  53 61 65 48 62 62 57 57 57 55 ...\n $ department: num  3 3 1 2 2 4 2 4 3 2 ...\n - attr(*, \".internal.selfref\")=&lt;externalptr&gt; \n - attr(*, \"sorted\")= chr \"patid\"\n\nsummary(walkingdata)\n\n     patid           group               time              walktime       \n Min.   :  1.00   Length:136         Length:136         Min.   :  0.0154  \n 1st Qu.: 34.75   Class :character   Class :character   1st Qu.:  2.1688  \n Median : 68.50   Mode  :character   Mode  :character   Median :  2.4287  \n Mean   : 68.52                                         Mean   :  4.1956  \n 3rd Qu.:102.25                                         3rd Qu.:  2.9491  \n Max.   :138.00                                         Max.   :185.3620  \n                                                        NA's   :1         \n     sex                 age          department   \n Length:136         Min.   :45.00   Min.   :1.000  \n Class :character   1st Qu.:54.00   1st Qu.:2.000  \n Mode  :character   Median :57.00   Median :3.000  \n                    Mean   :57.55   Mean   :2.596  \n                    3rd Qu.:60.25   3rd Qu.:3.250  \n                    Max.   :72.00   Max.   :4.000  \n                                                   \n\n\n\n\nDescribe\nOur first task was to describe the mean and standard deviation of walking time by group. There is no simple way to do this with base R. Possible tidyverse and data.table approaches are shown below.\n\n# Tidyverse\nwalkingdata %&gt;% \n  filter(!is.na(walktime)) %&gt;% \n  group_by(group) %&gt;% \n  summarise(Mean=mean(walktime), SD=sd(walktime))\n\n# A tibble: 2 × 3\n  group    Mean    SD\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 control  5.71 22.0 \n2 treated  2.61  2.00\n\n# data.table\nwalkingdata[!is.na(walktime) ,  \n            .(Mean=mean(walktime), SD=sd(walktime)),\n            group]\n\n     group     Mean        SD\n1: treated 2.609674  1.999246\n2: control 5.712487 22.011155\n\n\n\n\nVisualise\nBase R graphics are difficult to work with. ggplot2 provides an excellent system for graphing scientific data using R. See the associated slides and flipbook.\n\n# A very bad graph\nplot(walkingdata$age , walkingdata$walktime)\n\n\n\n# A better graph\nggplot(walkingdata) + \n  aes(x=age, y=walktime) + \n  geom_point()\n\nWarning: Removed 1 rows containing missing values (`geom_point()`).\n\n\n\n\n# Adorn the graph\nggplot(walkingdata) + \n  aes(x=age, y=walktime) + \n  geom_point() + \n  labs(x=\"Age (years)\", y=\"Time (seconds)\") + \n  scale_y_log10() + \n  facet_wrap(~sex) +\n  theme_bw()\n\nWarning: Removed 1 rows containing missing values (`geom_point()`).\n\n\n\n\nggplot(walkingdata) + \n  aes(x=group, y=walktime) + \n  geom_boxplot() + \n  labs(x=\"Treatment group\", y=\"Time (seconds)\") + \n  scale_y_log10() + \n  facet_wrap(~sex) +\n  theme_bw()\n\nWarning: Removed 1 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\n\n\nClean data\nOur graphics suggest that there are some data points that are probably technical failures. We should remove these.\n\n# base\nwalkingdata$walktime[ walkingdata$walktime &gt; 100 ] &lt;- NA\nwalkingdata$walktime[ walkingdata$walktime &lt; 0.1 ] &lt;- NA\n# data.table\nwalkingdata[ walktime&gt;100 , walktime := NA]\nwalkingdata[ walktime&lt;0.1 , walktime := NA]\n\n\n\nSimple tests\nNow we can conduct a simple statistical test of the walking speed across groups. Note the ‘formula’ interface:\n\nt.test( data = walkingdata , walktime ~ group)\n\n\n    Welch Two Sample t-test\n\ndata:  walktime by group\nt = 1.5788, df = 126.69, p-value = 0.1169\nalternative hypothesis: true difference in means between group control and group treated is not equal to 0\n95 percent confidence interval:\n -0.1283567  1.1413738\nsample estimates:\nmean in group control mean in group treated \n             3.116183              2.609674 \n\nttest1 &lt;- t.test( data = walkingdata , walktime ~ group)\nttest1$p.value\n\n[1] 0.1168802\n\n\nWhat does this suggest about the treatment effectiveness?\n\n\nModel\nThis test ignores much of what we know about these participants, and may not be suitable. A linear model is a better paradiagm for statistical analysis. It allows us to build more complex analyses, and easily test our assumptions.\n\nlm1 &lt;- lm( data = walkingdata , walktime ~ group)\nsummary(lm1)\n\n\nCall:\nlm(formula = walktime ~ group, data = walkingdata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.6223 -0.7297 -0.3963  0.0604 15.0317 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    3.1162     0.2257  13.806   &lt;2e-16 ***\ngrouptreated  -0.5065     0.3204  -1.581    0.116    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.848 on 131 degrees of freedom\n  (3 observations deleted due to missingness)\nMultiple R-squared:  0.01872,   Adjusted R-squared:  0.01123 \nF-statistic: 2.499 on 1 and 131 DF,  p-value: 0.1163\n\nconfint(lm1)\n\n                 2.5 %    97.5 %\n(Intercept)   2.669671 3.5626939\ngrouptreated -1.140358 0.1273411\n\n\n\n\nDiagnose\nThe diagnostics suggest something is wrong. We can transform the data so that the assumptions of the model are met.\n\nplot(lm1)\n\n\n\n\n\n\n\n\n\n\n\n\nwalkingdata[ , speed := 1/walktime]\n\nlm2 &lt;- lm( data = walkingdata , log(walktime) ~ group)\nlm3 &lt;- lm( data = walkingdata , 1/walktime ~ group)\nplot(lm2)\n\n\n\n\n\n\n\n\n\n\n\n\nplot(lm3)\n\n\n\n\n\n\n\n\n\n\n\n\nsummary(lm3)\n\n\nCall:\nlm(formula = 1/walktime ~ group, data = walkingdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.38121 -0.06170  0.00132  0.06453  0.30257 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   0.36681    0.01287  28.500  &lt; 2e-16 ***\ngrouptreated  0.07108    0.01827   3.891 0.000158 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1053 on 131 degrees of freedom\n  (3 observations deleted due to missingness)\nMultiple R-squared:  0.1036,    Adjusted R-squared:  0.09674 \nF-statistic: 15.14 on 1 and 131 DF,  p-value: 0.0001583\n\ngtsummary::tbl_regression(lm3)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    group\n\n\n\n        control\n—\n—\n\n        treated\n0.07\n0.03, 0.11\n&lt;0.001\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nIs the interpretation different now?\n\n\nAugment model\nWe can develop the model by adding terms for age and department. We should always include these because they explain variance in the outcome measure.\n\nlm4 &lt;- lm( data = walkingdata , 1/walktime ~ group + age + sex + department)\ngtsummary::tbl_regression(lm4)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    group\n\n\n\n        control\n—\n—\n\n        treated\n0.07\n0.04, 0.11\n&lt;0.001\n    age\n0.00\n-0.01, 0.00\n0.029\n    sex\n\n\n\n        F\n—\n—\n\n        M\n-0.01\n-0.05, 0.03\n0.6\n    department\n0.02\n0.00, 0.03\n0.060\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\nlm5 &lt;- lm( data = walkingdata , 1/walktime ~ group + age + sex + factor(department))\ngtsummary::tbl_regression(lm5)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    group\n\n\n\n        control\n—\n—\n\n        treated\n0.07\n0.03, 0.11\n&lt;0.001\n    age\n0.00\n-0.01, 0.00\n0.028\n    sex\n\n\n\n        F\n—\n—\n\n        M\n-0.01\n-0.05, 0.04\n0.7\n    factor(department)\n\n\n\n        1\n—\n—\n\n        2\n-0.01\n-0.06, 0.04\n0.7\n        3\n0.04\n-0.01, 0.09\n0.10\n        4\n0.03\n-0.02, 0.08\n0.2\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\nanova(lm5 , update(lm5, . ~ . -age))\n\nAnalysis of Variance Table\n\nModel 1: 1/walktime ~ group + age + sex + factor(department)\nModel 2: 1/walktime ~ group + sex + factor(department)\n  Res.Df    RSS Df Sum of Sq      F  Pr(&gt;F)  \n1    126 1.3190                              \n2    127 1.3709 -1 -0.051897 4.9574 0.02776 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nInteractions\nTo test whether the treatment effect varies by sex we should test the group*sex interaction.\n\nlm6 &lt;- lm( data = walkingdata , 1/walktime ~ group*sex + age +  factor(department))\n\ngtsummary::tbl_regression(lm6)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    group\n\n\n\n        control\n—\n—\n\n        treated\n0.05\n-0.02, 0.12\n0.14\n    sex\n\n\n\n        F\n—\n—\n\n        M\n-0.02\n-0.08, 0.04\n0.5\n    age\n0.00\n-0.01, 0.00\n0.029\n    factor(department)\n\n\n\n        1\n—\n—\n\n        2\n-0.01\n-0.07, 0.04\n0.6\n        3\n0.04\n-0.01, 0.09\n0.10\n        4\n0.03\n-0.02, 0.08\n0.2\n    group * sex\n\n\n\n        treated * M\n0.03\n-0.05, 0.11\n0.5\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\nanova( lm5 , lm6 )\n\nAnalysis of Variance Table\n\nModel 1: 1/walktime ~ group + age + sex + factor(department)\nModel 2: 1/walktime ~ group * sex + age + factor(department)\n  Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)\n1    126 1.3190                           \n2    125 1.3148  1 0.0042764 0.4066 0.5249\n\nlibrary(emmeans)\n\nWarning: package 'emmeans' was built under R version 4.2.3\n\nemmeans(lm6, pairwise ~ group | sex)\n\n$emmeans\nsex = F:\n group   emmean     SE  df lower.CL upper.CL\n control  0.379 0.0246 125    0.330    0.428\n treated  0.430 0.0260 125    0.379    0.482\n\nsex = M:\n group   emmean     SE  df lower.CL upper.CL\n control  0.359 0.0151 125    0.330    0.389\n treated  0.436 0.0150 125    0.407    0.466\n\nResults are averaged over the levels of: department \nConfidence level used: 0.95 \n\n$contrasts\nsex = F:\n contrast          estimate     SE  df t.ratio p.value\n control - treated  -0.0513 0.0346 125  -1.481  0.1411\n\nsex = M:\n contrast          estimate     SE  df t.ratio p.value\n control - treated  -0.0771 0.0211 125  -3.654  0.0004\n\nResults are averaged over the levels of: department \n\ntreatmentestimates &lt;- as.data.frame(confint(emmeans(lm6, pairwise ~ group | sex)$contrast))\n\n\ng1 &lt;- ggplot(treatmentestimates) + aes(x=sex, y=estimate, ymin=lower.CL, ymax=upper.CL) + \n  geom_point() + \n  geom_errorbar(width=0.2) + \n  geom_hline(yintercept = 0) + \n  theme_bw() + \n  labs(x=\"Sex\", y=\"Treatment effect\") \n  \ng1 \n\n\n\ng1 + coord_flip()\n\n\n\n\nWhat does this suggest. Does the treatment work in men and women?"
  }
]